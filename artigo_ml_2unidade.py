# -*- coding: utf-8 -*-
"""Artigo_ML_2unidade

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1a0U8ednbxC3pWDmA0tQMkHud-JIv6ohm
"""

!pip install yt_dlp

# --------------------------
# 1 - installs, imports e diret√≥rios (ATUALIZADO)
# --------------------------
# se rodando em notebook: descomente a linha abaixo para garantir libs
# !pip install numpy pandas matplotlib seaborn tqdm pillow librosa audioread yt-dlp ffmpeg-python scikit-learn xgboost tensorflow

import os, re, shutil, subprocess, math, random, json
import numpy as np
import pandas as pd
from tqdm import tqdm
from collections import defaultdict
from PIL import Image
import matplotlib.pyplot as plt

import librosa, librosa.display

import tensorflow as tf
from tensorflow.keras import layers, models, backend as K, callbacks, optimizers
from tensorflow.keras.applications import VGG16
from tensorflow.keras.utils import to_categorical
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix, precision_score, recall_score
import xgboost as xgb
import seaborn as sns

# Fixar seeds
SEED = 42
np.random.seed(SEED)
random.seed(SEED)
tf.random.set_seed(SEED)

# --------------------------
# Diret√≥rios principais (ajuste conforme seu Drive)
# --------------------------

ROOT_DIR = "/content/drive/MyDrive/M.L_2UNIDADE"   # caminho principal do projeto da 2¬™ unidade

# Estrutura de pastas
CSV_DIR     = os.path.join(ROOT_DIR, "csv_files")              # arquivos CSV do dataset
COOKIES_DIR = os.path.join(ROOT_DIR, "cookies")                # cookies yt-dlp (opcional)
WAV_DIR     = os.path.join(ROOT_DIR, "wav_files")              # cortes de √°udio WAV (10s)
IMG_DIR     = os.path.join(ROOT_DIR, "data-files")             # espectrogramas originais
AUG_DIR     = os.path.join(ROOT_DIR, "data-files-augmented")   # espectrogramas com augmentations
MODEL_DIR   = os.path.join(ROOT_DIR, "models_unit2")           # modelos treinados (VAE, CNNs)
RESULTS_DIR = os.path.join(ROOT_DIR, "results_unit2")          # m√©tricas, curvas ROC, matrizes de confus√£o

# Criar diret√≥rios caso n√£o existam
for d in [CSV_DIR, COOKIES_DIR, WAV_DIR, IMG_DIR, AUG_DIR, MODEL_DIR, RESULTS_DIR]:
    os.makedirs(d, exist_ok=True)

# Caminhos espec√≠ficos
CSV_PATH     = os.path.join(CSV_DIR, "unbalanced_train_segments.csv")  # caminho do CSV principal
COOKIES_PATH = os.path.join(COOKIES_DIR, "www.youtube.com_cookies.txt")                 # cookies yt-dlp (se necess√°rio)

# --------------------------
# Par√¢metros principais
# --------------------------
TARGET_PER_CLASS = 250    # n√∫mero de m√∫sicas por g√™nero
SR = 22050                # sample rate
CLIP_DURATION = 10        # dura√ß√£o dos clipes em segundos
IMG_WIDTH, IMG_HEIGHT = 224, 224
BATCH_SIZE = 32
VAE_EPOCHS = 2
CLASS_EPOCHS = 2
LATENT_DIM = 64
NOISE_FACTOR = 0.08
SPEC_AUG_TIME_MASKS = 2
SPEC_AUG_FREQ_MASKS = 2

RANDOM_STATE = SEED

# --------------------------
# G√™neros alvo (iguais ao c√≥digo original; pode ajustar se quiser)
# --------------------------
genre_dict = {
    '/m/064t9': 'Pop_music',
    '/m/0glt670': 'Hip_hop_music',
    '/m/06by7': 'Rock_music',
    '/m/06j6l': 'Rhythm_blues',
    '/m/06cqb': 'Reggae',
    '/m/0y4f8': 'Vocal',
    '/m/07gxw': 'Techno',
}

# --------------------------
# Helpers utilit√°rios
# --------------------------
def ensure_empty_dir(d):
    if os.path.exists(d):
        shutil.rmtree(d)
    os.makedirs(d, exist_ok=True)

def save_json(obj, path):
    with open(path, "w", encoding="utf-8") as f:
        json.dump(obj, f, indent=2, ensure_ascii=False)

def plot_and_save_fig(fig, filename):
    fig.tight_layout()
    fig.savefig(filename, dpi=200)
    plt.close(fig)

# --------------------------
# 2 - carregamento do dataset (leitura do CSV e filtragem por g√™neros)
# --------------------------
print("Etapa 2: lendo CSV e preparando candidatos...")
if not os.path.exists(CSV_PATH):
    raise FileNotFoundError(f"CSV n√£o encontrado em {CSV_PATH} - verifique caminho")

data = []
with open(CSV_PATH, "r", encoding="utf-8", errors="ignore") as f:
    for line in f:
        elements = re.sub(r'["\n]', "", line).split(",")
        if len(elements) >= 4:
            url = elements[0]; start = elements[1]; end = elements[2]; labels = elements[3:]
            for label in labels:
                if label in genre_dict:
                    data.append([url, start, end, genre_dict[label]])
df = pd.DataFrame(data, columns=["url", "start_time", "end_time", "class_label"])
df.to_csv(os.path.join(ROOT_DIR, "df_candidates_unit2.csv"), index=False)
print("Total candidatos lidos:", len(df))
print(df["class_label"].value_counts())

# --------------------------
# 3 - corte dos v√≠deos (download e cut) ‚Äî com retomada ordenada
# --------------------------
COOKIES_PATH = os.path.join(COOKIES_DIR, "www.youtube.com_cookies.txt")
print("\nEtapa 3: Download e corte dos v√≠deos (com retomada ordenada e verifica√ß√£o incremental).")

import yt_dlp
import pandas as pd
import os, subprocess

# üî∏ N√ÉO limpar o diret√≥rio
os.makedirs(WAV_DIR, exist_ok=True)

# üî∏ Verificar progresso anterior
progress_file = os.path.join(ROOT_DIR, "df_success_unit2.csv")
if os.path.exists(progress_file):
    df_success = pd.read_csv(progress_file)
    downloaded_ids = set(df_success["url"].astype(str))
    print(f"‚úÖ Retomando: {len(downloaded_ids)} v√≠deos j√° baixados com sucesso.")
else:
    df_success = pd.DataFrame(columns=["url", "start_time", "end_time", "class_label"])
    downloaded_ids = set()

# üî∏ Contar quantos arquivos WAV j√° existem por g√™nero
existing_files = [f for f in os.listdir(WAV_DIR) if f.endswith(".wav")]
existing_counts = {}
for f in existing_files:
    try:
        genre_name = f.split("_", 1)[1][:-4]
        existing_counts[genre_name] = existing_counts.get(genre_name, 0) + 1
    except:
        continue

counts = {label: existing_counts.get(label, 0) for label in genre_dict.values()}
print("üìä Arquivos j√° existentes por g√™nero:", counts)

# üî∏ Determinar o √∫ltimo v√≠deo baixado com sucesso (para cada g√™nero)
last_positions = {}
if not df_success.empty:
    for genre in df_success["class_label"].unique():
        last_url = df_success[df_success["class_label"] == genre]["url"].iloc[-1]
        try:
            pos = df[df["url"] == last_url].index[-1]
            last_positions[genre] = pos
        except IndexError:
            pass

# üî∏ Fun√ß√£o auxiliar: verificar se j√° existe WAV
def wav_exists(video_id, label):
    pattern = f"{video_id}_{label}.wav"
    return any(pattern in f for f in existing_files)

# üî∏ Baixar somente os g√™neros incompletos, continuando do √∫ltimo baixado
downloaded_rows = []
for label, group in df.groupby("class_label"):
    current_count = counts.get(label, 0)
    if current_count >= TARGET_PER_CLASS:
        print(f"‚úÖ {label} j√° completo ({current_count}/{TARGET_PER_CLASS}) - pulando.")
        continue

    # se houver posi√ß√£o salva, come√ßa dali
    start_index = last_positions.get(label, group.index[0])
    group = group.loc[group.index >= start_index]

    needed = TARGET_PER_CLASS - current_count
    print(f"\nüîπ {label}: precisa baixar {needed} arquivos (continuando ap√≥s √≠ndice {start_index}).")

    for idx, row in group.iterrows():
        vid = str(row["url"])
        start = float(row["start_time"])
        url = f"https://www.youtube.com/watch?v={vid}"
        final_file = os.path.join(WAV_DIR, f"{vid}_{label}.wav")

        # j√° baixado? pula
        if vid in downloaded_ids or wav_exists(vid, label):
            continue
        if counts[label] >= TARGET_PER_CLASS:
            print(f"üéØ {label} atingiu {TARGET_PER_CLASS}, parando.")
            break

        temp_out = os.path.join(WAV_DIR, f"temp_{vid}.%(ext)s")
        try:
            ydl_opts = {
                "format": "bestaudio/best",
                "outtmpl": temp_out,
                "quiet": True,
                "noplaylist": True
            }
            if os.path.exists(COOKIES_PATH):
                ydl_opts["cookiefile"] = COOKIES_PATH

            with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                ydl.download([url])

            temp_files = [f for f in os.listdir(WAV_DIR) if f.startswith(f"temp_{vid}")]
            if not temp_files:
                print(f"‚ö†Ô∏è Nenhum arquivo tempor√°rio gerado para {vid}")
                continue

            temp_file = os.path.join(WAV_DIR, temp_files[0])
            subprocess.run([
                "ffmpeg", "-y", "-ss", str(start), "-t", str(CLIP_DURATION),
                "-i", temp_file, "-acodec", "pcm_s16le", "-ar", str(SR), "-ac", "1", final_file
            ], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)

            os.remove(temp_file)
            if os.path.exists(final_file):
                counts[label] += 1
                downloaded_rows.append(row)
                downloaded_ids.add(vid)

                # salvar progresso incremental
                pd.concat([df_success, pd.DataFrame([row])]).to_csv(progress_file, index=False)

                if counts[label] % 10 == 0:
                    print(f"üéµ {counts[label]} baixados para {label}")

            else:
                print(f"‚ö†Ô∏è WAV n√£o gerado para {vid}")

        except Exception as e:
            print(f"‚ùå Erro ao baixar {vid}: {e}")
            continue

# üî∏ Salvar resumo
summary = pd.DataFrame(list(counts.items()), columns=["genre", "count"])
summary.to_csv(os.path.join(ROOT_DIR, "dataset_summary_unit2.csv"), index=False)

print("\n‚úÖ Download finalizado.")
for g, c in counts.items():
    print(f" - {g}: {c}/{TARGET_PER_CLASS}")
print("Progresso salvo em dataset_summary_unit2.csv e df_success_unit2.csv")

# --------------------------
# üîç Verifica√ß√£o e balanceamento dos arquivos WAV
# --------------------------
print("\n=== Verificando e balanceando os arquivos WAV ===")

import random
from collections import defaultdict, Counter

# listar todos os arquivos .wav
wav_files = [f for f in os.listdir(WAV_DIR) if f.endswith(".wav")]
if not wav_files:
    print("‚ö†Ô∏è Nenhum arquivo WAV encontrado em", WAV_DIR)

# 1Ô∏è‚É£ Contar arquivos por g√™nero
wav_by_genre = defaultdict(list)
for f in wav_files:
    try:
        genre = f.split("_")[-1].replace(".wav", "")
        wav_by_genre[genre].append(f)
    except:
        continue

print("\nüéµ Contagem inicial por g√™nero:")
for g, lst in wav_by_genre.items():
    print(f" - {g}: {len(lst)}")

# 2Ô∏è‚É£ Identificar duplicados pelo ID do v√≠deo
ids_seen = set()
duplicates = []
for f in wav_files:
    vid_id = f.split("_")[0]
    if vid_id in ids_seen:
        duplicates.append(f)
    ids_seen.add(vid_id)

# Remover duplicados
for dup in duplicates:
    try:
        os.remove(os.path.join(WAV_DIR, dup))
    except:
        pass

print(f"\nüîÅ Duplicados removidos: {len(duplicates)}")

# 3Ô∏è‚É£ Verificar e eliminar excessos (> TARGET_PER_CLASS)
for genre, files in wav_by_genre.items():
    # Atualizar lista ap√≥s remo√ß√£o
    current_files = [f for f in os.listdir(WAV_DIR) if f.endswith(f"_{genre}.wav")]
    if len(current_files) > TARGET_PER_CLASS:
        excess = len(current_files) - TARGET_PER_CLASS
        to_remove = random.sample(current_files, excess)
        for f in to_remove:
            os.remove(os.path.join(WAV_DIR, f))
        print(f"‚öñÔ∏è {genre}: removidos {excess} arquivos aleat√≥rios para balancear ({TARGET_PER_CLASS} restantes).")

# 4Ô∏è‚É£ Contagem final
final_counts = Counter([f.split("_")[-1].replace(".wav", "") for f in os.listdir(WAV_DIR) if f.endswith(".wav")])
print("\n‚úÖ Contagem final por g√™nero:")
for g, c in final_counts.items():
    print(f" - {g}: {c}")

# --------------------------
# 4 - Gerar os espectrogramas (MEL) - corrigido e incremental
# --------------------------
print("\nEtapa 4: Gerando espectrogramas MEL (uma pasta por g√™nero, incremental).")

import librosa, librosa.display
from PIL import Image
import matplotlib.pyplot as plt
from tqdm import tqdm

# N√£o limpar o diret√≥rio (mant√©m espectrogramas j√° gerados)
os.makedirs(IMG_DIR, exist_ok=True)

# Lista de arquivos WAV
wav_files = [f for f in os.listdir(WAV_DIR) if f.endswith(".wav")]
if not wav_files:
    print("‚ö†Ô∏è Nenhum arquivo WAV encontrado em", WAV_DIR)

# Gera espectrograma apenas se ainda n√£o existir o arquivo .jpg correspondente
for f in tqdm(wav_files, desc="Gerando espectrogramas"):
    try:
        # G√™nero √© a parte depois do √∫ltimo "_"
        parts = f.split("_")
        class_name = parts[-1].replace(".wav", "")
        class_dir = os.path.join(IMG_DIR, class_name)
        os.makedirs(class_dir, exist_ok=True)

        # Caminho de sa√≠da do espectrograma
        output_path = os.path.join(class_dir, f.replace(".wav", ".jpg"))
        if os.path.exists(output_path):
            continue  # pula se j√° existe

        # Carregar o √°udio
        y, sr = librosa.load(os.path.join(WAV_DIR, f), sr=SR)
        y = np.append(y[0], y[1:] - 0.97*y[:-1])  # pre-emphasis

        # Gerar espectrograma MEL (igual ao artigo original)
        M = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=2048,
                                           hop_length=512, n_mels=96, fmax=sr/2)
        log_power = librosa.power_to_db(M, ref=np.max)

        # Plotar e salvar imagem (sem eixos, fundo limpo)
        plt.figure(figsize=(3, 3))
        plt.axis("off")
        librosa.display.specshow(log_power, cmap="jet", sr=sr, hop_length=512)
        plt.savefig(output_path, bbox_inches="tight", pad_inches=0)
        plt.close()

    except Exception as e:
        print("Erro ao processar", f, "‚Üí", e)

# Contar quantas imagens por g√™nero
counts_img = {}
for g in os.listdir(IMG_DIR):
    gp = os.path.join(IMG_DIR, g)
    if os.path.isdir(gp):
        counts_img[g] = len([x for x in os.listdir(gp) if x.lower().endswith(".jpg")])

# Salvar estat√≠sticas
pd.DataFrame(list(counts_img.items()), columns=["genre", "images"])\
  .to_csv(os.path.join(ROOT_DIR, "image_counts_unit2.csv"), index=False)

print("\n‚úÖ Contagem de espectrogramas salva em image_counts_unit2.csv")
print("Resumo:", counts_img)

# --------------------------
# üîç Verifica√ß√£o e balanceamento dos espectrogramas
# --------------------------
print("\n=== Verificando e balanceando os espectrogramas ===")

import random
from collections import defaultdict, Counter

# 1Ô∏è‚É£ Contar arquivos por g√™nero
jpg_by_genre = defaultdict(list)
for genre_folder in os.listdir(IMG_DIR):
    genre_path = os.path.join(IMG_DIR, genre_folder)
    if not os.path.isdir(genre_path):
        continue
    for f in os.listdir(genre_path):
        if f.endswith(".jpg"):
            jpg_by_genre[genre_folder].append(f)

print("\nüñºÔ∏è Contagem inicial por g√™nero:")
for g, lst in jpg_by_genre.items():
    print(f" - {g}: {len(lst)}")

# 2Ô∏è‚É£ Identificar e remover duplicados
duplicates_jpg = []
for genre, files in jpg_by_genre.items():
    ids_seen = set()
    for f in files:
        vid_id = f.split("_")[0]
        if vid_id in ids_seen:
            duplicates_jpg.append((genre, f))
        ids_seen.add(vid_id)

for genre, f in duplicates_jpg:
    try:
        os.remove(os.path.join(IMG_DIR, genre, f))
    except:
        pass

print(f"\nüîÅ Duplicados removidos: {len(duplicates_jpg)}")

# 3Ô∏è‚É£ Se houver mais de TARGET_PER_CLASS, remover aleatoriamente
for genre, files in jpg_by_genre.items():
    current_files = [f for f in os.listdir(os.path.join(IMG_DIR, genre)) if f.endswith(".jpg")]
    if len(current_files) > TARGET_PER_CLASS:
        excess = len(current_files) - TARGET_PER_CLASS
        to_remove = random.sample(current_files, excess)
        for f in to_remove:
            os.remove(os.path.join(IMG_DIR, genre, f))
        print(f"‚öñÔ∏è {genre}: removidos {excess} espectrogramas aleat√≥rios (ficaram {TARGET_PER_CLASS}).")

# 4Ô∏è‚É£ Contagem final
final_counts_jpg = {}
for genre in os.listdir(IMG_DIR):
    genre_path = os.path.join(IMG_DIR, genre)
    if os.path.isdir(genre_path):
        count = len([f for f in os.listdir(genre_path) if f.endswith(".jpg")])
        final_counts_jpg[genre] = count

print("\n‚úÖ Contagem final por g√™nero:")
for g, c in final_counts_jpg.items():
    print(f" - {g}: {c}")

# --------------------------
# 5 - Criar e treinar o Autoencoder Variacional (VAE) ‚Äì vers√£o FINAL compat√≠vel com TF 2.15 / Keras 3
# --------------------------
print("\nEtapa 5: Criando e treinando o Autoencoder Variacional (VAE) ‚Äì vers√£o FINAL compat√≠vel com TF 2.15 / Keras 3.")

import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import os

# --------------------------
# CONFIGURA√á√ïES
# --------------------------
latent_dim = LATENT_DIM
input_shape = (IMG_HEIGHT, IMG_WIDTH, 3)

# caminhos salvos no formato moderno
encoder_path = os.path.join(MODEL_DIR, "encoder_unit2_final.keras")
decoder_path = os.path.join(MODEL_DIR, "decoder_unit2_final.keras")
vae_weights_path = os.path.join(MODEL_DIR, "vae_unit2_final.weights.h5")

# --------------------------
# DADOS
# --------------------------
datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255, validation_split=0.1)

train_gen = datagen.flow_from_directory(
    IMG_DIR,
    target_size=(IMG_HEIGHT, IMG_WIDTH),
    batch_size=BATCH_SIZE,
    class_mode=None,
    subset='training',
    shuffle=True,
    seed=SEED
)

val_gen = datagen.flow_from_directory(
    IMG_DIR,
    target_size=(IMG_HEIGHT, IMG_WIDTH),
    batch_size=BATCH_SIZE,
    class_mode=None,
    subset='validation',
    shuffle=True,
    seed=SEED
)

# --------------------------
# ENCODER
# --------------------------
encoder_inputs = layers.Input(shape=input_shape, name="encoder_input")
x = layers.Conv2D(32, 3, strides=2, padding="same", activation="relu")(encoder_inputs)
x = layers.Conv2D(64, 3, strides=2, padding="same", activation="relu")(x)
x = layers.Conv2D(128, 3, strides=2, padding="same", activation="relu")(x)
x = layers.Flatten()(x)
x = layers.Dense(256, activation="relu")(x)
z_mean = layers.Dense(latent_dim, name="z_mean")(x)
z_log_var = layers.Dense(latent_dim, name="z_log_var")(x)

def sampling(args):
    z_mean, z_log_var = args
    epsilon = tf.random.normal(shape=tf.shape(z_mean))
    return z_mean + tf.exp(0.5 * z_log_var) * epsilon

z = layers.Lambda(sampling, name="z")([z_mean, z_log_var])
encoder = models.Model(encoder_inputs, [z_mean, z_log_var, z], name="encoder")
encoder.summary()

# --------------------------
# DECODER
# --------------------------
latent_inputs = layers.Input(shape=(latent_dim,), name="z_sampling")
x = layers.Dense(28 * 28 * 64, activation="relu")(latent_inputs)
x = layers.Reshape((28, 28, 64))(x)
x = layers.Conv2DTranspose(128, 3, strides=2, padding="same", activation="relu")(x)
x = layers.Conv2DTranspose(64, 3, strides=2, padding="same", activation="relu")(x)
x = layers.Conv2DTranspose(32, 3, strides=2, padding="same", activation="relu")(x)
decoder_outputs = layers.Conv2DTranspose(3, 3, activation="sigmoid", padding="same")(x)
decoder = models.Model(latent_inputs, decoder_outputs, name="decoder")
decoder.summary()

# --------------------------
# CLASSE VAE PERSONALIZADA
# --------------------------
class VAE(tf.keras.Model):
    def __init__(self, encoder, decoder, **kwargs):
        super(VAE, self).__init__(**kwargs)
        self.encoder = encoder
        self.decoder = decoder
        self.total_loss_tracker = tf.keras.metrics.Mean(name="loss")
        self.recon_loss_tracker = tf.keras.metrics.Mean(name="recon_loss")
        self.kl_loss_tracker = tf.keras.metrics.Mean(name="kl_loss")

    def call(self, inputs):
        z_mean, z_log_var, z = self.encoder(inputs)
        return self.decoder(z)

    def compute_losses(self, data):
        z_mean, z_log_var, z = self.encoder(data)
        reconstruction = self.decoder(z)
        bce = tf.keras.losses.binary_crossentropy(data, reconstruction)
        reconstruction_loss = tf.reduce_mean(tf.reduce_sum(bce, axis=(1, 2)))
        kl_loss = -0.5 * tf.reduce_mean(
            tf.reduce_sum(1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var), axis=1)
        )
        total_loss = reconstruction_loss + kl_loss
        return total_loss, reconstruction_loss, kl_loss

    def train_step(self, data):
        if isinstance(data, tuple):
            data = data[0]
        with tf.GradientTape() as tape:
            total_loss, reconstruction_loss, kl_loss = self.compute_losses(data)
        grads = tape.gradient(total_loss, self.trainable_weights)
        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))
        self.total_loss_tracker.update_state(total_loss)
        self.recon_loss_tracker.update_state(reconstruction_loss)
        self.kl_loss_tracker.update_state(kl_loss)
        return {
            "loss": self.total_loss_tracker.result(),
            "recon_loss": self.recon_loss_tracker.result(),
            "kl_loss": self.kl_loss_tracker.result(),
        }

    def test_step(self, data):
        if isinstance(data, tuple):
            data = data[0]
        total_loss, reconstruction_loss, kl_loss = self.compute_losses(data)
        self.total_loss_tracker.update_state(total_loss)
        self.recon_loss_tracker.update_state(reconstruction_loss)
        self.kl_loss_tracker.update_state(kl_loss)
        return {
            "val_loss": self.total_loss_tracker.result(),
            "val_recon_loss": self.recon_loss_tracker.result(),
            "val_kl_loss": self.kl_loss_tracker.result(),
        }

# --------------------------
# COMPILAR E TREINAR
# --------------------------
vae = VAE(encoder, decoder)
vae.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4))

if not os.path.exists(vae_weights_path):
    print("üß† Treinando VAE (vers√£o final compat√≠vel)...")
    vae.fit(
        train_gen,
        validation_data=val_gen,
        epochs=VAE_EPOCHS,
        verbose=1
    )

    # ‚öôÔ∏è build antes de salvar pesos
    vae.build((None, *input_shape))

    # salvar nos formatos modernos
    vae.encoder.save(encoder_path)
    vae.decoder.save(decoder_path)
    vae.save_weights(vae_weights_path)

    print("‚úÖ VAE treinado e salvo com sucesso (.keras / .weights.h5)")
else:
    print("‚öôÔ∏è Carregando pesos VAE existentes...")
    vae.build((None, *input_shape))
    vae.encoder.load_weights(encoder_path, skip_mismatch=True)
    vae.decoder.load_weights(decoder_path, skip_mismatch=True)
    print("‚úÖ Modelos encoder/decoder carregados.")

# --------------------------
# 6 - Criar augmenta√ß√µes (novas abordagens)
# --------------------------
print("\nEtapa 6: criando augmenta√ß√µes (reconstru√ß√µes VAE, interpola√ß√£o latente, SpecAugment, spectral mix)")

ensure_empty_dir(AUG_DIR)
for g in sorted(os.listdir(IMG_DIR)):
    os.makedirs(os.path.join(AUG_DIR, g), exist_ok=True)

# 6A: Reconstru√ß√µes ruidosas (VAE reconstruction of noisy input)
def reconstruct_with_vae(X, batch=32):
    recs = vae.predict(X, batch_size=batch)
    return recs

# gerar reconstru√ß√µes para cada imagem de treino (uma por amostra)
for i, p in enumerate(tqdm(train_paths)):
    cls = train_y[i]
    # carregar imagem
    img = Image.open(os.path.join(IMG_DIR, p)).convert("RGB").resize((IMG_WIDTH, IMG_HEIGHT))
    arr = np.array(img, dtype=np.float32)/255.0
    noisy = add_noise(np.expand_dims(arr,0), NOISE_FACTOR)
    rec = vae.predict(noisy)[0]
    outname = os.path.splitext(os.path.basename(p))[0] + "_vae_rec.jpg"
    Image.fromarray((rec*255).astype(np.uint8)).save(os.path.join(AUG_DIR, cls, outname))

# 6B: Interpola√ß√£o no espa√ßo latente (entre pares da mesma classe e entre classes similares)
N_INTERP_PER_CLASS = 2
# Criar encoder model (input image -> z_mean) para obter m√©dias latentes para interpola√ß√£o
encoder_model = models.Model(inputs, z_mean)  # usar z_mean (determin√≠stico) para interpolar de forma est√°vel

for cls in sorted(set(train_y)):
    class_indices = [i for i,lab in enumerate(train_y) if lab==cls]
    if len(class_indices) < 2: continue
    chosen = np.random.choice(class_indices, size=min(len(class_indices), 10), replace=False)
    for k in range(N_INTERP_PER_CLASS):
        a,b = np.random.choice(chosen, size=2, replace=False)
        img_a = np.array(Image.open(os.path.join(IMG_DIR, train_paths[a])).convert("RGB").resize((IMG_WIDTH,IMG_HEIGHT)), dtype=np.float32)/255.0
        img_b = np.array(Image.open(os.path.join(IMG_DIR, train_paths[b])).convert("RGB").resize((IMG_WIDTH,IMG_HEIGHT)), dtype=np.float32)/255.0
        za = encoder_model.predict(img_a[np.newaxis,...])[0]
        zb = encoder_model.predict(img_b[np.newaxis,...])[0]
        alpha = np.random.uniform(0.25, 0.75)
        zint = alpha * za + (1-alpha) * zb
        rec = decoder.predict(zint[np.newaxis,...])[0]
        outname = f"interp_{k}_{os.path.basename(train_paths[a])}_{os.path.basename(train_paths[b])}.jpg"
        Image.fromarray((np.clip(rec,0,1)*255).astype(np.uint8)).save(os.path.join(AUG_DIR, cls, outname))

# 6C: SpecAugment (aplicado diretamente nos espectrogramas antes de salvar)
def spec_augment_image(img_arr, time_masks=SPEC_AUG_TIME_MASKS, freq_masks=SPEC_AUG_FREQ_MASKS, max_time_mask_pct=0.2, max_freq_mask_pct=0.15):
    # img_arr in [0,1], shape (H,W,C) but SpecAugment manipulates spectral axis (H=n_mels) and time axis (W)
    img = img_arr.copy()
    H, W = img.shape[0], img.shape[1]
    for _ in range(time_masks):
        t = int(np.random.uniform(0.0, max_time_mask_pct) * W)
        t0 = np.random.randint(0, max(1, W - t + 1))
        img[:, t0:t0+t, :] = 0
    for _ in range(freq_masks):
        f = int(np.random.uniform(0.0, max_freq_mask_pct) * H)
        f0 = np.random.randint(0, max(1, H - f + 1))
        img[f0:f0+f, :, :] = 0
    return img

# Aplicar SpecAugment a algumas imagens de treino e salvar
N_SPEC_AUG_PER_CLASS = 2
for cls in sorted(set(train_y)):
    class_indices = [i for i,lab in enumerate(train_y) if lab==cls]
    chosen = np.random.choice(class_indices, size=min(len(class_indices), 20), replace=False)
    for i_idx in chosen[:N_SPEC_AUG_PER_CLASS]:
        p = train_paths[i_idx]
        arr = np.array(Image.open(os.path.join(IMG_DIR, p)).convert("RGB").resize((IMG_WIDTH, IMG_HEIGHT)), dtype=np.float32)/255.0
        aug = spec_augment_image(arr)
        outname = os.path.splitext(os.path.basename(p))[0] + "_specaug.jpg"
        Image.fromarray((np.clip(aug,0,1)*255).astype(np.uint8)).save(os.path.join(AUG_DIR, cls, outname))

# 6D: Spectral Mix (linear mix of two spectrogram images) - naive mix (hard label use original or duplicate)
N_MIX_PER_CLASS = 2
for cls in sorted(set(train_y)):
    class_indices = [i for i,lab in enumerate(train_y) if lab==cls]
    if len(class_indices) < 2: continue
    chosen = np.random.choice(class_indices, size=min(len(class_indices), 20), replace=False)
    for k in range(N_MIX_PER_CLASS):
        a,b = np.random.choice(chosen, size=2, replace=False)
        arr_a = np.array(Image.open(os.path.join(IMG_DIR, train_paths[a])).convert("RGB").resize((IMG_WIDTH,IMG_HEIGHT)), dtype=np.float32)/255.0
        arr_b = np.array(Image.open(os.path.join(IMG_DIR, train_paths[b])).convert("RGB").resize((IMG_WIDTH,IMG_HEIGHT)), dtype=np.float32)/255.0
        alpha = np.random.uniform(0.3, 0.7)
        mixed = alpha*arr_a + (1-alpha)*arr_b
        outname = f"mix_{k}_{os.path.basename(train_paths[a])}_{os.path.basename(train_paths[b])}.jpg"
        Image.fromarray((np.clip(mixed,0,1)*255).astype(np.uint8)).save(os.path.join(AUG_DIR, cls, outname))

# 6E: finalmente, copiamos os originais para AUG_DIR (mant√©m originais + artificially generated)
for p, y in zip(train_paths, train_y):
    src = os.path.join(IMG_DIR, p)
    dst = os.path.join(AUG_DIR, y, os.path.basename(p))
    if not os.path.exists(dst):
        shutil.copy(src, dst)

# salvar resumo de quantos arquivos por classe no AUG_DIR
aug_counts = {g: len([f for f in os.listdir(os.path.join(AUG_DIR,g)) if f.lower().endswith(".jpg")]) for g in os.listdir(AUG_DIR)}
pd.DataFrame(list(aug_counts.items()), columns=["genre","aug_images"]).to_csv(os.path.join(ROOT_DIR, "aug_image_counts_unit2.csv"), index=False)
print("Augmentation conclu√≠da. Counts saved to aug_image_counts_unit2.csv")

# --------------------------
# 7 - Testes: treinar 2 CNNs
#   - CNN A: VGG16 transfer learning com dados originais (baseline)
#   - CNN B: VGG16 transfer learning com dados originais + AUG_DIR
# --------------------------
print("\nEtapa 7: treinar CNNs baseline e augmented")

# Fun√ß√µes auxiliares para coletar arquivos
def collect_files_labels(root):
    files, labels = [], []
    for cls in sorted(os.listdir(root)):
        cls_dir = os.path.join(root, cls)
        if not os.path.isdir(cls_dir): continue
        for f in os.listdir(cls_dir):
            if f.lower().endswith(".jpg"):
                files.append(os.path.join(cls_dir, f))
                labels.append(cls)
    return files, labels

orig_files, orig_labels = collect_files_labels(IMG_DIR)
aug_files, aug_labels = collect_files_labels(AUG_DIR)

# Criar splits (para compara√ß√£o justa manter o mesmo test set - usar test_paths criados anteriormente)
# We'll use test_paths list (relative paths) to define test set file paths in IMG_DIR
test_file_paths = [os.path.join(IMG_DIR, p) for p in test_paths]

# Create function to split train/val for baseline using orig_files excluding test_files
def split_files_for_training(files, labels, test_file_paths, val_frac=0.2):
    # filter out test
    files_filtered, labels_filtered = [], []
    for f, l in zip(files, labels):
        if os.path.abspath(f) in [os.path.abspath(x) for x in test_file_paths]:
            continue
        files_filtered.append(f); labels_filtered.append(l)
    tr_files, val_files, tr_labels, val_labels = train_test_split(files_filtered, labels_filtered, test_size=val_frac, stratify=labels_filtered, random_state=RANDOM_STATE)
    return tr_files, val_files, tr_labels, val_labels

train_files_base, val_files_base, train_labels_base, val_labels_base = split_files_for_training(orig_files, orig_labels, test_file_paths)
train_files_aug, val_files_aug, train_labels_aug, val_labels_aug = split_files_for_training(aug_files, aug_labels, test_file_paths)

print("Baseline train size:", len(train_files_base), "val:", len(val_files_base), "test:", len(test_file_paths))
print("Augmented train size:", len(train_files_aug), "val:", len(val_files_aug), "test:", len(test_file_paths))

# Generator Keras Sequence
from tensorflow.keras.utils import Sequence
class ImageSequence(Sequence):
    def __init__(self, files, labels, le, batch_size=BATCH_SIZE, shuffle=True, augment=False):
        self.files = files
        self.labels = np.array(labels)
        self.le = le
        self.batch_size = batch_size
        self.shuffle = shuffle
        self.augment = augment
        self.indexes = np.arange(len(self.files))
        self.on_epoch_end()
    def __len__(self):
        return math.ceil(len(self.files)/self.batch_size)
    def __getitem__(self, idx):
        batch_idx = self.indexes[idx*self.batch_size:(idx+1)*self.batch_size]
        batch_files = [self.files[i] for i in batch_idx]
        batch_labels = self.labels[batch_idx]
        imgs = []
        for p in batch_files:
            img = Image.open(p).convert("RGB").resize((IMG_WIDTH,IMG_HEIGHT))
            arr = np.array(img, dtype=np.float32)/255.0
            if self.augment:
                # apply random small transforms: horizontal flip, small brightness jitter, spec augment occasionally
                if random.random() < 0.1:
                    arr = np.fliplr(arr)
                if random.random() < 0.2:
                    arr = np.clip(arr + 0.03 * np.random.randn(*arr.shape), 0, 1)
            imgs.append(arr)
        X = np.stack(imgs)
        y = to_categorical(self.le.transform(batch_labels), num_classes=len(self.le.classes_))
        return X, y
    def on_epoch_end(self):
        if self.shuffle:
            np.random.shuffle(self.indexes)

# label encoder based on classes found
le_classes = LabelEncoder()
le_classes.fit(sorted(os.listdir(IMG_DIR)))

# Create generators
train_gen_base = ImageSequence(train_files_base, train_labels_base, le_classes, batch_size=BATCH_SIZE, shuffle=True, augment=False)
val_gen_base = ImageSequence(val_files_base, val_labels_base, le_classes, batch_size=BATCH_SIZE, shuffle=False, augment=False)
train_gen_aug = ImageSequence(train_files_aug, train_labels_aug, le_classes, batch_size=BATCH_SIZE, shuffle=True, augment=True)
val_gen_aug = ImageSequence(val_files_aug, val_labels_aug, le_classes, batch_size=BATCH_SIZE, shuffle=False, augment=False)
test_gen = ImageSequence(test_file_paths, test_y, le_classes, batch_size=BATCH_SIZE, shuffle=False, augment=False)

# Build VGG16 transfer model factory
def build_vgg_transfer(num_classes, train_base=False):
    base = VGG16(include_top=False, weights='imagenet', input_shape=(IMG_WIDTH,IMG_HEIGHT,3))
    base.trainable = train_base
    inp = layers.Input(shape=(IMG_WIDTH,IMG_HEIGHT,3))
    x = base(inp, training=False)
    x = layers.Flatten()(x)
    x = layers.Dense(512, activation='relu')(x)
    x = layers.Dropout(0.3)(x)
    out = layers.Dense(num_classes, activation='softmax')(x)
    model = models.Model(inp, out)
    model.compile(optimizer=optimizers.Adam(1e-5), loss='categorical_crossentropy', metrics=['accuracy'])
    return model

num_classes = len(le_classes.classes_)
print("Num classes:", num_classes)

# Train baseline
print("Treinando VGG16 baseline (originais)...")
vgg_base = build_vgg_transfer(num_classes, train_base=False)
es = callbacks.EarlyStopping(patience=4, restore_best_weights=True)
history_base = vgg_base.fit(train_gen_base, epochs=CLASS_EPOCHS, validation_data=val_gen_base, callbacks=[es])
vgg_base.save(os.path.join(MODEL_DIR, "vgg_base_unit2.h5"))

# Evaluate baseline
def evaluate_keras_model(model, seq):
    y_true, y_pred, y_prob = [], [], []
    for Xb, yb in seq:
        probs = model.predict(Xb)
        preds = np.argmax(probs, axis=1)
        y_pred.extend(preds.tolist())
        y_prob.extend(probs.tolist())
        y_true.extend(np.argmax(yb, axis=1).tolist())
    return np.array(y_true), np.array(y_pred), np.array(y_prob)

y_true_base, y_pred_base, y_prob_base = evaluate_keras_model(vgg_base, test_gen)
acc_base = accuracy_score(y_true_base, y_pred_base)
f1_base = f1_score(y_true_base, y_pred_base, average='macro')
print("Baseline: Acc", acc_base, "F1", f1_base)

# Train augmented
print("Treinando VGG16 com dataset aumentado...")
vgg_aug = build_vgg_transfer(num_classes, train_base=False)
history_aug = vgg_aug.fit(train_gen_aug, epochs=CLASS_EPOCHS, validation_data=val_gen_aug, callbacks=[es])
vgg_aug.save(os.path.join(MODEL_DIR, "vgg_aug_unit2.h5"))

y_true_aug, y_pred_aug, y_prob_aug = evaluate_keras_model(vgg_aug, test_gen)
acc_aug = accuracy_score(y_true_aug, y_pred_aug)
f1_aug = f1_score(y_true_aug, y_pred_aug, average='macro')
print("Augmented: Acc", acc_aug, "F1", f1_aug)

# --------------------------
# 8 - Resultados: tabela, ROC e matrizes de confus√£o
# --------------------------
print("\nEtapa 8: Gerando m√©tricas, curvas ROC e matrizes de confus√£o (sem PDF).")

from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve, auc
from sklearn.preprocessing import label_binarize
import seaborn as sns
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

# Cria√ß√£o da tabela de m√©tricas
y_test_bin = label_binarize(y_true_base, classes=np.arange(num_classes))
try:
    auc_base = roc_auc_score(y_test_bin, y_prob_base, average='macro')
except Exception:
    auc_base = np.nan
try:
    auc_aug = roc_auc_score(y_test_bin, y_prob_aug, average='macro')
except Exception:
    auc_aug = np.nan

metrics_df = pd.DataFrame([
    ["VGG16 (baseline)", acc_base, f1_base, auc_base],
    ["VGG16 (augmented)", acc_aug, f1_aug, auc_aug]
], columns=["Model", "Accuracy", "F1_macro", "AUC_macro"])

# Salvar tabela
metrics_path = os.path.join(RESULTS_DIR, "metrics_comparison_unit2.csv")
metrics_df.to_csv(metrics_path, index=False)
print("\nüìä Tabela de m√©tricas:")
print(metrics_df)
print(f"\nTabela salva em: {metrics_path}")

# --------------------------
# Curvas ROC
# --------------------------
def multiclass_roc(y_true, y_prob, n_classes):
    y_bin = label_binarize(y_true, classes=np.arange(n_classes))
    fpr, tpr, roc_auc = {}, {}, {}
    for i in range(n_classes):
        try:
            fpr[i], tpr[i], _ = roc_curve(y_bin[:, i], np.array(y_prob)[:, i])
            roc_auc[i] = auc(fpr[i], tpr[i])
        except:
            fpr[i], tpr[i], roc_auc[i] = None, None, None
    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes) if fpr[i] is not None]))
    mean_tpr = np.zeros_like(all_fpr)
    for i in range(n_classes):
        if fpr[i] is not None:
            mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])
    mean_tpr /= n_classes
    fpr["macro"], tpr["macro"], roc_auc["macro"] = all_fpr, mean_tpr, auc(all_fpr, mean_tpr)
    return fpr, tpr, roc_auc

fpr_b, tpr_b, roc_auc_b = multiclass_roc(y_true_base, y_prob_base, num_classes)
fpr_a, tpr_a, roc_auc_a = multiclass_roc(y_true_aug, y_prob_aug, num_classes)

plt.figure(figsize=(8,6))
plt.plot(fpr_b["macro"], tpr_b["macro"], '--', label=f'Baseline (AUC={roc_auc_b["macro"]:.3f})')
plt.plot(fpr_a["macro"], tpr_a["macro"], '-.', label=f'Augmented (AUC={roc_auc_a["macro"]:.3f})')
plt.plot([0,1],[0,1],'k--')
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve - Compara√ß√£o (Macro Average)")
plt.legend()
plt.grid(alpha=0.3)
roc_path = os.path.join(RESULTS_DIR, "roc_comparison.png")
plt.savefig(roc_path, dpi=200)
plt.close()
print(f"‚úÖ Curva ROC salva em: {roc_path}")

# --------------------------
# Matrizes de confus√£o
# --------------------------
cm_base = confusion_matrix(y_true_base, y_pred_base)
cm_aug  = confusion_matrix(y_true_aug, y_pred_aug)

# Baseline
plt.figure(figsize=(10,8))
sns.heatmap(cm_base, annot=True, fmt="d", cmap="Blues",
            xticklabels=le_classes.classes_, yticklabels=le_classes.classes_)
plt.title("Matriz de Confus√£o - CNN Base")
plt.xlabel("Predito"); plt.ylabel("Real")
cm_base_path = os.path.join(RESULTS_DIR, "cm_baseline.png")
plt.savefig(cm_base_path, dpi=200)
plt.close()

# Augmented
plt.figure(figsize=(10,8))
sns.heatmap(cm_aug, annot=True, fmt="d", cmap="Greens",
            xticklabels=le_classes.classes_, yticklabels=le_classes.classes_)
plt.title("Matriz de Confus√£o - CNN com Augmentation")
plt.xlabel("Predito"); plt.ylabel("Real")
cm_aug_path = os.path.join(RESULTS_DIR, "cm_augmented.png")
plt.savefig(cm_aug_path, dpi=200)
plt.close()

print(f"‚úÖ Matrizes salvas em:\n - {cm_base_path}\n - {cm_aug_path}")

print("\nüéØ Resultados finais conclu√≠dos! Verifique os arquivos na pasta 'results_unit2'")