{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install yt_dlp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4TelpVnVcZbg",
        "outputId": "34d96fb0-f14d-4c63-fdb5-b814435f9ccd"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting yt_dlp\n",
            "  Downloading yt_dlp-2025.10.14-py3-none-any.whl.metadata (175 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.9/175.9 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading yt_dlp-2025.10.14-py3-none-any.whl (3.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: yt_dlp\n",
            "Successfully installed yt_dlp-2025.10.14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "5CfscjXKvl8l"
      },
      "outputs": [],
      "source": [
        "# --------------------------\n",
        "# 1 - installs, imports e diretórios (ATUALIZADO)\n",
        "# --------------------------\n",
        "# se rodando em notebook: descomente a linha abaixo para garantir libs\n",
        "# !pip install numpy pandas matplotlib seaborn tqdm pillow librosa audioread yt-dlp ffmpeg-python scikit-learn xgboost tensorflow\n",
        "\n",
        "import os, re, shutil, subprocess, math, random, json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from collections import defaultdict\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import librosa, librosa.display\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, backend as K, callbacks, optimizers\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix, precision_score, recall_score\n",
        "import xgboost as xgb\n",
        "import seaborn as sns\n",
        "\n",
        "# Fixar seeds\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "# --------------------------\n",
        "# Diretórios principais (ajuste conforme seu Drive)\n",
        "# --------------------------\n",
        "\n",
        "ROOT_DIR = \"/content/drive/MyDrive/M.L_2UNIDADE\"   # caminho principal do projeto da 2ª unidade\n",
        "\n",
        "# Estrutura de pastas\n",
        "CSV_DIR     = os.path.join(ROOT_DIR, \"csv_files\")              # arquivos CSV do dataset\n",
        "COOKIES_DIR = os.path.join(ROOT_DIR, \"cookies\")                # cookies yt-dlp (opcional)\n",
        "WAV_DIR     = os.path.join(ROOT_DIR, \"wav_files\")              # cortes de áudio WAV (10s)\n",
        "IMG_DIR     = os.path.join(ROOT_DIR, \"data-files\")             # espectrogramas originais\n",
        "AUG_DIR     = os.path.join(ROOT_DIR, \"data-files-augmented\")   # espectrogramas com augmentations\n",
        "MODEL_DIR   = os.path.join(ROOT_DIR, \"models_unit2\")           # modelos treinados (VAE, CNNs)\n",
        "RESULTS_DIR = os.path.join(ROOT_DIR, \"results_unit2\")          # métricas, curvas ROC, matrizes de confusão\n",
        "\n",
        "# Criar diretórios caso não existam\n",
        "for d in [CSV_DIR, COOKIES_DIR, WAV_DIR, IMG_DIR, AUG_DIR, MODEL_DIR, RESULTS_DIR]:\n",
        "    os.makedirs(d, exist_ok=True)\n",
        "\n",
        "# Caminhos específicos\n",
        "CSV_PATH     = os.path.join(CSV_DIR, \"unbalanced_train_segments.csv\")  # caminho do CSV principal\n",
        "COOKIES_PATH = os.path.join(COOKIES_DIR, \"www.youtube.com_cookies.txt\")                 # cookies yt-dlp (se necessário)\n",
        "\n",
        "# --------------------------\n",
        "# Parâmetros principais\n",
        "# --------------------------\n",
        "TARGET_PER_CLASS = 250    # número de músicas por gênero\n",
        "SR = 22050                # sample rate\n",
        "CLIP_DURATION = 10        # duração dos clipes em segundos\n",
        "IMG_WIDTH, IMG_HEIGHT = 224, 224\n",
        "BATCH_SIZE = 32\n",
        "VAE_EPOCHS = 2\n",
        "CLASS_EPOCHS = 2\n",
        "LATENT_DIM = 64\n",
        "NOISE_FACTOR = 0.08\n",
        "SPEC_AUG_TIME_MASKS = 2\n",
        "SPEC_AUG_FREQ_MASKS = 2\n",
        "\n",
        "RANDOM_STATE = SEED\n",
        "\n",
        "# --------------------------\n",
        "# Gêneros alvo (iguais ao código original; pode ajustar se quiser)\n",
        "# --------------------------\n",
        "genre_dict = {\n",
        "    '/m/064t9': 'Pop_music',\n",
        "    '/m/0glt670': 'Hip_hop_music',\n",
        "    '/m/06by7': 'Rock_music',\n",
        "    '/m/06j6l': 'Rhythm_blues',\n",
        "    '/m/06cqb': 'Reggae',\n",
        "    '/m/0y4f8': 'Vocal',\n",
        "    '/m/07gxw': 'Techno',\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------\n",
        "# Helpers utilitários\n",
        "# --------------------------\n",
        "def ensure_empty_dir(d):\n",
        "    if os.path.exists(d):\n",
        "        shutil.rmtree(d)\n",
        "    os.makedirs(d, exist_ok=True)\n",
        "\n",
        "def save_json(obj, path):\n",
        "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(obj, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "def plot_and_save_fig(fig, filename):\n",
        "    fig.tight_layout()\n",
        "    fig.savefig(filename, dpi=200)\n",
        "    plt.close(fig)"
      ],
      "metadata": {
        "id": "REzTtoBDyTop"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------\n",
        "# 2 - carregamento do dataset (leitura do CSV e filtragem por gêneros)\n",
        "# --------------------------\n",
        "print(\"Etapa 2: lendo CSV e preparando candidatos...\")\n",
        "if not os.path.exists(CSV_PATH):\n",
        "    raise FileNotFoundError(f\"CSV não encontrado em {CSV_PATH} - verifique caminho\")\n",
        "\n",
        "data = []\n",
        "with open(CSV_PATH, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "    for line in f:\n",
        "        elements = re.sub(r'[\"\\n]', \"\", line).split(\",\")\n",
        "        if len(elements) >= 4:\n",
        "            url = elements[0]; start = elements[1]; end = elements[2]; labels = elements[3:]\n",
        "            for label in labels:\n",
        "                if label in genre_dict:\n",
        "                    data.append([url, start, end, genre_dict[label]])\n",
        "df = pd.DataFrame(data, columns=[\"url\", \"start_time\", \"end_time\", \"class_label\"])\n",
        "df.to_csv(os.path.join(ROOT_DIR, \"df_candidates_unit2.csv\"), index=False)\n",
        "print(\"Total candidatos lidos:\", len(df))\n",
        "print(df[\"class_label\"].value_counts())"
      ],
      "metadata": {
        "id": "MN4zR-23yXin",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac9574c3-781a-421c-c19b-3dcd7c31a0fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Etapa 2: lendo CSV e preparando candidatos...\n",
            "Total candidatos lidos: 51710\n",
            "class_label\n",
            "Techno           16811\n",
            "Pop_music         8407\n",
            "Rock_music        8198\n",
            "Hip_hop_music     7370\n",
            "Rhythm_blues      4755\n",
            "Vocal             3241\n",
            "Reggae            2928\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------\n",
        "# 3 - corte dos vídeos (download e cut) — com retomada ordenada\n",
        "# --------------------------\n",
        "COOKIES_PATH = os.path.join(COOKIES_DIR, \"www.youtube.com_cookies.txt\")\n",
        "print(\"\\nEtapa 3: Download e corte dos vídeos (com retomada ordenada e verificação incremental).\")\n",
        "\n",
        "import yt_dlp\n",
        "import pandas as pd\n",
        "import os, subprocess\n",
        "\n",
        "# 🔸 NÃO limpar o diretório\n",
        "os.makedirs(WAV_DIR, exist_ok=True)\n",
        "\n",
        "# 🔸 Verificar progresso anterior\n",
        "progress_file = os.path.join(ROOT_DIR, \"df_success_unit2.csv\")\n",
        "if os.path.exists(progress_file):\n",
        "    df_success = pd.read_csv(progress_file)\n",
        "    downloaded_ids = set(df_success[\"url\"].astype(str))\n",
        "    print(f\"✅ Retomando: {len(downloaded_ids)} vídeos já baixados com sucesso.\")\n",
        "else:\n",
        "    df_success = pd.DataFrame(columns=[\"url\", \"start_time\", \"end_time\", \"class_label\"])\n",
        "    downloaded_ids = set()\n",
        "\n",
        "# 🔸 Contar quantos arquivos WAV já existem por gênero\n",
        "existing_files = [f for f in os.listdir(WAV_DIR) if f.endswith(\".wav\")]\n",
        "existing_counts = {}\n",
        "for f in existing_files:\n",
        "    try:\n",
        "        genre_name = f.split(\"_\", 1)[1][:-4]\n",
        "        existing_counts[genre_name] = existing_counts.get(genre_name, 0) + 1\n",
        "    except:\n",
        "        continue\n",
        "\n",
        "counts = {label: existing_counts.get(label, 0) for label in genre_dict.values()}\n",
        "print(\"📊 Arquivos já existentes por gênero:\", counts)\n",
        "\n",
        "# 🔸 Determinar o último vídeo baixado com sucesso (para cada gênero)\n",
        "last_positions = {}\n",
        "if not df_success.empty:\n",
        "    for genre in df_success[\"class_label\"].unique():\n",
        "        last_url = df_success[df_success[\"class_label\"] == genre][\"url\"].iloc[-1]\n",
        "        try:\n",
        "            pos = df[df[\"url\"] == last_url].index[-1]\n",
        "            last_positions[genre] = pos\n",
        "        except IndexError:\n",
        "            pass\n",
        "\n",
        "# 🔸 Função auxiliar: verificar se já existe WAV\n",
        "def wav_exists(video_id, label):\n",
        "    pattern = f\"{video_id}_{label}.wav\"\n",
        "    return any(pattern in f for f in existing_files)\n",
        "\n",
        "# 🔸 Baixar somente os gêneros incompletos, continuando do último baixado\n",
        "downloaded_rows = []\n",
        "for label, group in df.groupby(\"class_label\"):\n",
        "    current_count = counts.get(label, 0)\n",
        "    if current_count >= TARGET_PER_CLASS:\n",
        "        print(f\"✅ {label} já completo ({current_count}/{TARGET_PER_CLASS}) - pulando.\")\n",
        "        continue\n",
        "\n",
        "    # se houver posição salva, começa dali\n",
        "    start_index = last_positions.get(label, group.index[0])\n",
        "    group = group.loc[group.index >= start_index]\n",
        "\n",
        "    needed = TARGET_PER_CLASS - current_count\n",
        "    print(f\"\\n🔹 {label}: precisa baixar {needed} arquivos (continuando após índice {start_index}).\")\n",
        "\n",
        "    for idx, row in group.iterrows():\n",
        "        vid = str(row[\"url\"])\n",
        "        start = float(row[\"start_time\"])\n",
        "        url = f\"https://www.youtube.com/watch?v={vid}\"\n",
        "        final_file = os.path.join(WAV_DIR, f\"{vid}_{label}.wav\")\n",
        "\n",
        "        # já baixado? pula\n",
        "        if vid in downloaded_ids or wav_exists(vid, label):\n",
        "            continue\n",
        "        if counts[label] >= TARGET_PER_CLASS:\n",
        "            print(f\"🎯 {label} atingiu {TARGET_PER_CLASS}, parando.\")\n",
        "            break\n",
        "\n",
        "        temp_out = os.path.join(WAV_DIR, f\"temp_{vid}.%(ext)s\")\n",
        "        try:\n",
        "            ydl_opts = {\n",
        "                \"format\": \"bestaudio/best\",\n",
        "                \"outtmpl\": temp_out,\n",
        "                \"quiet\": True,\n",
        "                \"noplaylist\": True\n",
        "            }\n",
        "            if os.path.exists(COOKIES_PATH):\n",
        "                ydl_opts[\"cookiefile\"] = COOKIES_PATH\n",
        "\n",
        "            with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "                ydl.download([url])\n",
        "\n",
        "            temp_files = [f for f in os.listdir(WAV_DIR) if f.startswith(f\"temp_{vid}\")]\n",
        "            if not temp_files:\n",
        "                print(f\"⚠️ Nenhum arquivo temporário gerado para {vid}\")\n",
        "                continue\n",
        "\n",
        "            temp_file = os.path.join(WAV_DIR, temp_files[0])\n",
        "            subprocess.run([\n",
        "                \"ffmpeg\", \"-y\", \"-ss\", str(start), \"-t\", str(CLIP_DURATION),\n",
        "                \"-i\", temp_file, \"-acodec\", \"pcm_s16le\", \"-ar\", str(SR), \"-ac\", \"1\", final_file\n",
        "            ], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "\n",
        "            os.remove(temp_file)\n",
        "            if os.path.exists(final_file):\n",
        "                counts[label] += 1\n",
        "                downloaded_rows.append(row)\n",
        "                downloaded_ids.add(vid)\n",
        "\n",
        "                # salvar progresso incremental\n",
        "                pd.concat([df_success, pd.DataFrame([row])]).to_csv(progress_file, index=False)\n",
        "\n",
        "                if counts[label] % 10 == 0:\n",
        "                    print(f\"🎵 {counts[label]} baixados para {label}\")\n",
        "\n",
        "            else:\n",
        "                print(f\"⚠️ WAV não gerado para {vid}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Erro ao baixar {vid}: {e}\")\n",
        "            continue\n",
        "\n",
        "# 🔸 Salvar resumo\n",
        "summary = pd.DataFrame(list(counts.items()), columns=[\"genre\", \"count\"])\n",
        "summary.to_csv(os.path.join(ROOT_DIR, \"dataset_summary_unit2.csv\"), index=False)\n",
        "\n",
        "print(\"\\n✅ Download finalizado.\")\n",
        "for g, c in counts.items():\n",
        "    print(f\" - {g}: {c}/{TARGET_PER_CLASS}\")\n",
        "print(\"Progresso salvo em dataset_summary_unit2.csv e df_success_unit2.csv\")\n"
      ],
      "metadata": {
        "id": "VJ2sofWSyawI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "153c9427-7445-4459-c59e-9f6a1dcceeb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Etapa 3: Download e corte dos vídeos (com retomada ordenada e verificação incremental).\n",
            "✅ Retomando: 11 vídeos já baixados com sucesso.\n",
            "📊 Arquivos já existentes por gênero: {'Pop_music': 250, 'Hip_hop_music': 250, 'Rock_music': 249, 'Rhythm_blues': 250, 'Reggae': 250, 'Vocal': 234, 'Techno': 250}\n",
            "✅ Hip_hop_music já completo (250/250) - pulando.\n",
            "✅ Pop_music já completo (250/250) - pulando.\n",
            "✅ Reggae já completo (250/250) - pulando.\n",
            "✅ Rhythm_blues já completo (250/250) - pulando.\n",
            "\n",
            "🔹 Rock_music: precisa baixar 1 arquivos (continuando após índice 3).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: [youtube] The provided YouTube account cookies are no longer valid. They have likely been rotated in the browser as a security measure. For tips on how to effectively export YouTube cookies, refer to  https://github.com/yt-dlp/yt-dlp/wiki/Extractors#exporting-youtube-cookies .\n",
            "WARNING: [youtube] The provided YouTube account cookies are no longer valid. They have likely been rotated in the browser as a security measure. For tips on how to effectively export YouTube cookies, refer to  https://github.com/yt-dlp/yt-dlp/wiki/Extractors#exporting-youtube-cookies .\n",
            "WARNING: [youtube] The provided YouTube account cookies are no longer valid. They have likely been rotated in the browser as a security measure. For tips on how to effectively export YouTube cookies, refer to  https://github.com/yt-dlp/yt-dlp/wiki/Extractors#exporting-youtube-cookies .\n",
            "WARNING: [youtube] The provided YouTube account cookies are no longer valid. They have likely been rotated in the browser as a security measure. For tips on how to effectively export YouTube cookies, refer to  https://github.com/yt-dlp/yt-dlp/wiki/Extractors#exporting-youtube-cookies .\n",
            "ERROR: [youtube] -08IuAXloCI: Video unavailable\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "❌ Erro ao baixar -08IuAXloCI: ERROR: [youtube] -08IuAXloCI: Video unavailable\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR: [youtube] -5HSR5eWEDU: Video unavailable\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "❌ Erro ao baixar -5HSR5eWEDU: ERROR: [youtube] -5HSR5eWEDU: Video unavailable\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR: [youtube] -82OBRkQskQ: Private video. Sign in if you've been granted access to this video. Use --cookies-from-browser or --cookies for the authentication. See  https://github.com/yt-dlp/yt-dlp/wiki/FAQ#how-do-i-pass-cookies-to-yt-dlp  for how to manually pass cookies. Also see  https://github.com/yt-dlp/yt-dlp/wiki/Extractors#exporting-youtube-cookies  for tips on effectively exporting YouTube cookies\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "❌ Erro ao baixar -82OBRkQskQ: ERROR: [youtube] -82OBRkQskQ: Private video. Sign in if you've been granted access to this video. Use --cookies-from-browser or --cookies for the authentication. See  https://github.com/yt-dlp/yt-dlp/wiki/FAQ#how-do-i-pass-cookies-to-yt-dlp  for how to manually pass cookies. Also see  https://github.com/yt-dlp/yt-dlp/wiki/Extractors#exporting-youtube-cookies  for tips on effectively exporting YouTube cookies\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR: [youtube] -LTES9d6dZY: Video unavailable\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "❌ Erro ao baixar -LTES9d6dZY: ERROR: [youtube] -LTES9d6dZY: Video unavailable\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR: [youtube] -TdKFIt-tlY: Video unavailable\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "❌ Erro ao baixar -TdKFIt-tlY: ERROR: [youtube] -TdKFIt-tlY: Video unavailable\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR: [youtube] -XCNxDxsAL0: Video unavailable. This video is no longer available due to a copyright claim by Rock & Roll Hall of Fame\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "❌ Erro ao baixar -XCNxDxsAL0: ERROR: [youtube] -XCNxDxsAL0: Video unavailable. This video is no longer available due to a copyright claim by Rock & Roll Hall of Fame\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR: [youtube] -aA0j_NIJcg: Video unavailable. This video is no longer available because the YouTube account associated with this video has been terminated.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "❌ Erro ao baixar -aA0j_NIJcg: ERROR: [youtube] -aA0j_NIJcg: Video unavailable. This video is no longer available because the YouTube account associated with this video has been terminated.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR: [youtube] -fTW98nVe1g: Video unavailable. This video contains content from SME, who has blocked it in your country on copyright grounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "❌ Erro ao baixar -fTW98nVe1g: ERROR: [youtube] -fTW98nVe1g: Video unavailable. This video contains content from SME, who has blocked it in your country on copyright grounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR: [youtube] -hrpU1nxsbc: Video unavailable\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "❌ Erro ao baixar -hrpU1nxsbc: ERROR: [youtube] -hrpU1nxsbc: Video unavailable\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR: [youtube] -lAVvperqpQ: Video unavailable\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "❌ Erro ao baixar -lAVvperqpQ: ERROR: [youtube] -lAVvperqpQ: Video unavailable\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR: [youtube] -pRIE4KkY1M: Video unavailable. This video is no longer available due to a copyright claim by Coda Publishing Ltd\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "❌ Erro ao baixar -pRIE4KkY1M: ERROR: [youtube] -pRIE4KkY1M: Video unavailable. This video is no longer available due to a copyright claim by Coda Publishing Ltd\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR: [youtube] 061qiXuzrQs: Video unavailable. This video is no longer available due to a copyright claim by Studio Hamburg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "❌ Erro ao baixar 061qiXuzrQs: ERROR: [youtube] 061qiXuzrQs: Video unavailable. This video is no longer available due to a copyright claim by Studio Hamburg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR: [youtube] 0AQvRSZ8ZNo: Video unavailable. This video is no longer available because the YouTube account associated with this video has been terminated.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "❌ Erro ao baixar 0AQvRSZ8ZNo: ERROR: [youtube] 0AQvRSZ8ZNo: Video unavailable. This video is no longer available because the YouTube account associated with this video has been terminated.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR: [youtube] 0H3VllGZQEU: Video unavailable\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "❌ Erro ao baixar 0H3VllGZQEU: ERROR: [youtube] 0H3VllGZQEU: Video unavailable\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR: [youtube] 0Ma-YlsySuU: Video unavailable. This video is no longer available because the YouTube account associated with this video has been terminated.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "❌ Erro ao baixar 0Ma-YlsySuU: ERROR: [youtube] 0Ma-YlsySuU: Video unavailable. This video is no longer available because the YouTube account associated with this video has been terminated.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR: [youtube] 0YRM3tkIXfA: Video unavailable. This video is no longer available because the YouTube account associated with this video has been terminated.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "❌ Erro ao baixar 0YRM3tkIXfA: ERROR: [youtube] 0YRM3tkIXfA: Video unavailable. This video is no longer available because the YouTube account associated with this video has been terminated.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR: [youtube] 0q_EX7TiuV8: Video unavailable. This video is no longer available because the YouTube account associated with this video has been terminated.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "❌ Erro ao baixar 0q_EX7TiuV8: ERROR: [youtube] 0q_EX7TiuV8: Video unavailable. This video is no longer available because the YouTube account associated with this video has been terminated.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR: [youtube] 0sMqbNNwzvU: Video unavailable. This video is no longer available because the YouTube account associated with this video has been terminated.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "❌ Erro ao baixar 0sMqbNNwzvU: ERROR: [youtube] 0sMqbNNwzvU: Video unavailable. This video is no longer available because the YouTube account associated with this video has been terminated.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR: [youtube] 0sqcvMHyQ1k: Video unavailable\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "❌ Erro ao baixar 0sqcvMHyQ1k: ERROR: [youtube] 0sqcvMHyQ1k: Video unavailable\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR: [youtube] 0z7EpFwegJM: Private video. Sign in if you've been granted access to this video. Use --cookies-from-browser or --cookies for the authentication. See  https://github.com/yt-dlp/yt-dlp/wiki/FAQ#how-do-i-pass-cookies-to-yt-dlp  for how to manually pass cookies. Also see  https://github.com/yt-dlp/yt-dlp/wiki/Extractors#exporting-youtube-cookies  for tips on effectively exporting YouTube cookies\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "❌ Erro ao baixar 0z7EpFwegJM: ERROR: [youtube] 0z7EpFwegJM: Private video. Sign in if you've been granted access to this video. Use --cookies-from-browser or --cookies for the authentication. See  https://github.com/yt-dlp/yt-dlp/wiki/FAQ#how-do-i-pass-cookies-to-yt-dlp  for how to manually pass cookies. Also see  https://github.com/yt-dlp/yt-dlp/wiki/Extractors#exporting-youtube-cookies  for tips on effectively exporting YouTube cookies\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR: [youtube] 1-Oahk8L_Og: Video unavailable\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "❌ Erro ao baixar 1-Oahk8L_Og: ERROR: [youtube] 1-Oahk8L_Og: Video unavailable\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR: [youtube] 1A8piNIeg6w: Video unavailable\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "❌ Erro ao baixar 1A8piNIeg6w: ERROR: [youtube] 1A8piNIeg6w: Video unavailable\n",
            "🎵 250 baixados para Rock_music\n",
            "🎯 Rock_music atingiu 250, parando.\n",
            "✅ Techno já completo (250/250) - pulando.\n",
            "\n",
            "🔹 Vocal: precisa baixar 16 arquivos (continuando após índice 46199).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR: [youtube] piAVTNAiZto: Video unavailable. This video is no longer available because the YouTube account associated with this video has been terminated.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "❌ Erro ao baixar piAVTNAiZto: ERROR: [youtube] piAVTNAiZto: Video unavailable. This video is no longer available because the YouTube account associated with this video has been terminated.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR: [youtube] pkcKUTIWoUA: Video unavailable\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "❌ Erro ao baixar pkcKUTIWoUA: ERROR: [youtube] pkcKUTIWoUA: Video unavailable\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR: [youtube] povpzIiWNhA: Video unavailable. This video is no longer available due to a copyright claim by EG Productions\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "❌ Erro ao baixar povpzIiWNhA: ERROR: [youtube] povpzIiWNhA: Video unavailable. This video is no longer available due to a copyright claim by EG Productions\n",
            "🎵 240 baixados para Vocal\n",
            "🎵 250 baixados para Vocal\n",
            "🎯 Vocal atingiu 250, parando.\n",
            "\n",
            "✅ Download finalizado.\n",
            " - Pop_music: 250/250\n",
            " - Hip_hop_music: 250/250\n",
            " - Rock_music: 250/250\n",
            " - Rhythm_blues: 250/250\n",
            " - Reggae: 250/250\n",
            " - Vocal: 250/250\n",
            " - Techno: 250/250\n",
            "Progresso salvo em dataset_summary_unit2.csv e df_success_unit2.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------\n",
        "# 🔍 Verificação e balanceamento dos arquivos WAV\n",
        "# --------------------------\n",
        "print(\"\\n=== Verificando e balanceando os arquivos WAV ===\")\n",
        "\n",
        "import random\n",
        "from collections import defaultdict, Counter\n",
        "\n",
        "# listar todos os arquivos .wav\n",
        "wav_files = [f for f in os.listdir(WAV_DIR) if f.endswith(\".wav\")]\n",
        "if not wav_files:\n",
        "    print(\"⚠️ Nenhum arquivo WAV encontrado em\", WAV_DIR)\n",
        "\n",
        "# 1️⃣ Contar arquivos por gênero\n",
        "wav_by_genre = defaultdict(list)\n",
        "for f in wav_files:\n",
        "    try:\n",
        "        genre = f.split(\"_\")[-1].replace(\".wav\", \"\")\n",
        "        wav_by_genre[genre].append(f)\n",
        "    except:\n",
        "        continue\n",
        "\n",
        "print(\"\\n🎵 Contagem inicial por gênero:\")\n",
        "for g, lst in wav_by_genre.items():\n",
        "    print(f\" - {g}: {len(lst)}\")\n",
        "\n",
        "# 2️⃣ Identificar duplicados pelo ID do vídeo\n",
        "ids_seen = set()\n",
        "duplicates = []\n",
        "for f in wav_files:\n",
        "    vid_id = f.split(\"_\")[0]\n",
        "    if vid_id in ids_seen:\n",
        "        duplicates.append(f)\n",
        "    ids_seen.add(vid_id)\n",
        "\n",
        "# Remover duplicados\n",
        "for dup in duplicates:\n",
        "    try:\n",
        "        os.remove(os.path.join(WAV_DIR, dup))\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "print(f\"\\n🔁 Duplicados removidos: {len(duplicates)}\")\n",
        "\n",
        "# 3️⃣ Verificar e eliminar excessos (> TARGET_PER_CLASS)\n",
        "for genre, files in wav_by_genre.items():\n",
        "    # Atualizar lista após remoção\n",
        "    current_files = [f for f in os.listdir(WAV_DIR) if f.endswith(f\"_{genre}.wav\")]\n",
        "    if len(current_files) > TARGET_PER_CLASS:\n",
        "        excess = len(current_files) - TARGET_PER_CLASS\n",
        "        to_remove = random.sample(current_files, excess)\n",
        "        for f in to_remove:\n",
        "            os.remove(os.path.join(WAV_DIR, f))\n",
        "        print(f\"⚖️ {genre}: removidos {excess} arquivos aleatórios para balancear ({TARGET_PER_CLASS} restantes).\")\n",
        "\n",
        "# 4️⃣ Contagem final\n",
        "final_counts = Counter([f.split(\"_\")[-1].replace(\".wav\", \"\") for f in os.listdir(WAV_DIR) if f.endswith(\".wav\")])\n",
        "print(\"\\n✅ Contagem final por gênero:\")\n",
        "for g, c in final_counts.items():\n",
        "    print(f\" - {g}: {c}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xlwXd557mSdU",
        "outputId": "e892e37e-1e28-4f24-ca25-20aab10678fc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Verificando e balanceando os arquivos WAV ===\n",
            "\n",
            "🎵 Contagem inicial por gênero:\n",
            " - Reggae: 250\n",
            " - music: 250\n",
            " - blues: 250\n",
            " - Techno: 250\n",
            " - Vocal: 250\n",
            "\n",
            "🔁 Duplicados removidos: 0\n",
            "\n",
            "✅ Contagem final por gênero:\n",
            " - Reggae: 250\n",
            " - music: 250\n",
            " - blues: 250\n",
            " - Techno: 250\n",
            " - Vocal: 250\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------\n",
        "# 4 - Gerar os espectrogramas (MEL) - corrigido e incremental\n",
        "# --------------------------\n",
        "print(\"\\nEtapa 4: Gerando espectrogramas MEL (uma pasta por gênero, incremental).\")\n",
        "\n",
        "import librosa, librosa.display\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Não limpar o diretório (mantém espectrogramas já gerados)\n",
        "os.makedirs(IMG_DIR, exist_ok=True)\n",
        "\n",
        "# Lista de arquivos WAV\n",
        "wav_files = [f for f in os.listdir(WAV_DIR) if f.endswith(\".wav\")]\n",
        "if not wav_files:\n",
        "    print(\"⚠️ Nenhum arquivo WAV encontrado em\", WAV_DIR)\n",
        "\n",
        "# Gera espectrograma apenas se ainda não existir o arquivo .jpg correspondente\n",
        "for f in tqdm(wav_files, desc=\"Gerando espectrogramas\"):\n",
        "    try:\n",
        "        # Gênero é a parte depois do último \"_\"\n",
        "        parts = f.split(\"_\")\n",
        "        class_name = parts[-1].replace(\".wav\", \"\")\n",
        "        class_dir = os.path.join(IMG_DIR, class_name)\n",
        "        os.makedirs(class_dir, exist_ok=True)\n",
        "\n",
        "        # Caminho de saída do espectrograma\n",
        "        output_path = os.path.join(class_dir, f.replace(\".wav\", \".jpg\"))\n",
        "        if os.path.exists(output_path):\n",
        "            continue  # pula se já existe\n",
        "\n",
        "        # Carregar o áudio\n",
        "        y, sr = librosa.load(os.path.join(WAV_DIR, f), sr=SR)\n",
        "        y = np.append(y[0], y[1:] - 0.97*y[:-1])  # pre-emphasis\n",
        "\n",
        "        # Gerar espectrograma MEL (igual ao artigo original)\n",
        "        M = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=2048,\n",
        "                                           hop_length=512, n_mels=96, fmax=sr/2)\n",
        "        log_power = librosa.power_to_db(M, ref=np.max)\n",
        "\n",
        "        # Plotar e salvar imagem (sem eixos, fundo limpo)\n",
        "        plt.figure(figsize=(3, 3))\n",
        "        plt.axis(\"off\")\n",
        "        librosa.display.specshow(log_power, cmap=\"jet\", sr=sr, hop_length=512)\n",
        "        plt.savefig(output_path, bbox_inches=\"tight\", pad_inches=0)\n",
        "        plt.close()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"Erro ao processar\", f, \"→\", e)\n",
        "\n",
        "# Contar quantas imagens por gênero\n",
        "counts_img = {}\n",
        "for g in os.listdir(IMG_DIR):\n",
        "    gp = os.path.join(IMG_DIR, g)\n",
        "    if os.path.isdir(gp):\n",
        "        counts_img[g] = len([x for x in os.listdir(gp) if x.lower().endswith(\".jpg\")])\n",
        "\n",
        "# Salvar estatísticas\n",
        "pd.DataFrame(list(counts_img.items()), columns=[\"genre\", \"images\"])\\\n",
        "  .to_csv(os.path.join(ROOT_DIR, \"image_counts_unit2.csv\"), index=False)\n",
        "\n",
        "print(\"\\n✅ Contagem de espectrogramas salva em image_counts_unit2.csv\")\n",
        "print(\"Resumo:\", counts_img)\n"
      ],
      "metadata": {
        "id": "03SuC-p7yueR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff882a3f-9fde-44b8-db6d-90f563e5105b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Etapa 4: Gerando espectrogramas MEL (uma pasta por gênero, incremental).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Gerando espectrogramas: 100%|██████████| 1250/1250 [03:19<00:00,  6.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Contagem de espectrogramas salva em image_counts_unit2.csv\n",
            "Resumo: {'blues': 250, 'music': 250, 'Techno': 250, 'Vocal': 250, 'Reggae': 250}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------\n",
        "# 🔍 Verificação e balanceamento dos espectrogramas\n",
        "# --------------------------\n",
        "print(\"\\n=== Verificando e balanceando os espectrogramas ===\")\n",
        "\n",
        "import random\n",
        "from collections import defaultdict, Counter\n",
        "\n",
        "# 1️⃣ Contar arquivos por gênero\n",
        "jpg_by_genre = defaultdict(list)\n",
        "for genre_folder in os.listdir(IMG_DIR):\n",
        "    genre_path = os.path.join(IMG_DIR, genre_folder)\n",
        "    if not os.path.isdir(genre_path):\n",
        "        continue\n",
        "    for f in os.listdir(genre_path):\n",
        "        if f.endswith(\".jpg\"):\n",
        "            jpg_by_genre[genre_folder].append(f)\n",
        "\n",
        "print(\"\\n🖼️ Contagem inicial por gênero:\")\n",
        "for g, lst in jpg_by_genre.items():\n",
        "    print(f\" - {g}: {len(lst)}\")\n",
        "\n",
        "# 2️⃣ Identificar e remover duplicados\n",
        "duplicates_jpg = []\n",
        "for genre, files in jpg_by_genre.items():\n",
        "    ids_seen = set()\n",
        "    for f in files:\n",
        "        vid_id = f.split(\"_\")[0]\n",
        "        if vid_id in ids_seen:\n",
        "            duplicates_jpg.append((genre, f))\n",
        "        ids_seen.add(vid_id)\n",
        "\n",
        "for genre, f in duplicates_jpg:\n",
        "    try:\n",
        "        os.remove(os.path.join(IMG_DIR, genre, f))\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "print(f\"\\n🔁 Duplicados removidos: {len(duplicates_jpg)}\")\n",
        "\n",
        "# 3️⃣ Se houver mais de TARGET_PER_CLASS, remover aleatoriamente\n",
        "for genre, files in jpg_by_genre.items():\n",
        "    current_files = [f for f in os.listdir(os.path.join(IMG_DIR, genre)) if f.endswith(\".jpg\")]\n",
        "    if len(current_files) > TARGET_PER_CLASS:\n",
        "        excess = len(current_files) - TARGET_PER_CLASS\n",
        "        to_remove = random.sample(current_files, excess)\n",
        "        for f in to_remove:\n",
        "            os.remove(os.path.join(IMG_DIR, genre, f))\n",
        "        print(f\"⚖️ {genre}: removidos {excess} espectrogramas aleatórios (ficaram {TARGET_PER_CLASS}).\")\n",
        "\n",
        "# 4️⃣ Contagem final\n",
        "final_counts_jpg = {}\n",
        "for genre in os.listdir(IMG_DIR):\n",
        "    genre_path = os.path.join(IMG_DIR, genre)\n",
        "    if os.path.isdir(genre_path):\n",
        "        count = len([f for f in os.listdir(genre_path) if f.endswith(\".jpg\")])\n",
        "        final_counts_jpg[genre] = count\n",
        "\n",
        "print(\"\\n✅ Contagem final por gênero:\")\n",
        "for g, c in final_counts_jpg.items():\n",
        "    print(f\" - {g}: {c}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpdX2MeiTQvk",
        "outputId": "47b2e023-6c94-44d4-d949-d223dec0804a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Verificando e balanceando os espectrogramas ===\n",
            "\n",
            "🖼️ Contagem inicial por gênero:\n",
            " - blues: 250\n",
            " - music: 250\n",
            " - Techno: 250\n",
            " - Vocal: 250\n",
            " - Reggae: 250\n",
            "\n",
            "🔁 Duplicados removidos: 0\n",
            "\n",
            "✅ Contagem final por gênero:\n",
            " - blues: 250\n",
            " - music: 250\n",
            " - Techno: 250\n",
            " - Vocal: 250\n",
            " - Reggae: 250\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------\n",
        "# 5 - Criar e treinar o Autoencoder Variacional (VAE) – versão FINAL compatível com TF 2.15 / Keras 3\n",
        "# --------------------------\n",
        "print(\"\\nEtapa 5: Criando e treinando o Autoencoder Variacional (VAE) – versão FINAL compatível com TF 2.15 / Keras 3.\")\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "\n",
        "# --------------------------\n",
        "# CONFIGURAÇÕES\n",
        "# --------------------------\n",
        "latent_dim = LATENT_DIM\n",
        "input_shape = (IMG_HEIGHT, IMG_WIDTH, 3)\n",
        "\n",
        "# caminhos salvos no formato moderno\n",
        "encoder_path = os.path.join(MODEL_DIR, \"encoder_unit2_final.keras\")\n",
        "decoder_path = os.path.join(MODEL_DIR, \"decoder_unit2_final.keras\")\n",
        "vae_weights_path = os.path.join(MODEL_DIR, \"vae_unit2_final.weights.h5\")\n",
        "\n",
        "# --------------------------\n",
        "# DADOS\n",
        "# --------------------------\n",
        "datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255, validation_split=0.1)\n",
        "\n",
        "train_gen = datagen.flow_from_directory(\n",
        "    IMG_DIR,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode=None,\n",
        "    subset='training',\n",
        "    shuffle=True,\n",
        "    seed=SEED\n",
        ")\n",
        "\n",
        "val_gen = datagen.flow_from_directory(\n",
        "    IMG_DIR,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode=None,\n",
        "    subset='validation',\n",
        "    shuffle=True,\n",
        "    seed=SEED\n",
        ")\n",
        "\n",
        "# --------------------------\n",
        "# ENCODER\n",
        "# --------------------------\n",
        "encoder_inputs = layers.Input(shape=input_shape, name=\"encoder_input\")\n",
        "x = layers.Conv2D(32, 3, strides=2, padding=\"same\", activation=\"relu\")(encoder_inputs)\n",
        "x = layers.Conv2D(64, 3, strides=2, padding=\"same\", activation=\"relu\")(x)\n",
        "x = layers.Conv2D(128, 3, strides=2, padding=\"same\", activation=\"relu\")(x)\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(256, activation=\"relu\")(x)\n",
        "z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
        "z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
        "\n",
        "def sampling(args):\n",
        "    z_mean, z_log_var = args\n",
        "    epsilon = tf.random.normal(shape=tf.shape(z_mean))\n",
        "    return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
        "\n",
        "z = layers.Lambda(sampling, name=\"z\")([z_mean, z_log_var])\n",
        "encoder = models.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
        "encoder.summary()\n",
        "\n",
        "# --------------------------\n",
        "# DECODER\n",
        "# --------------------------\n",
        "latent_inputs = layers.Input(shape=(latent_dim,), name=\"z_sampling\")\n",
        "x = layers.Dense(28 * 28 * 64, activation=\"relu\")(latent_inputs)\n",
        "x = layers.Reshape((28, 28, 64))(x)\n",
        "x = layers.Conv2DTranspose(128, 3, strides=2, padding=\"same\", activation=\"relu\")(x)\n",
        "x = layers.Conv2DTranspose(64, 3, strides=2, padding=\"same\", activation=\"relu\")(x)\n",
        "x = layers.Conv2DTranspose(32, 3, strides=2, padding=\"same\", activation=\"relu\")(x)\n",
        "decoder_outputs = layers.Conv2DTranspose(3, 3, activation=\"sigmoid\", padding=\"same\")(x)\n",
        "decoder = models.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
        "decoder.summary()\n",
        "\n",
        "# --------------------------\n",
        "# CLASSE VAE PERSONALIZADA\n",
        "# --------------------------\n",
        "class VAE(tf.keras.Model):\n",
        "    def __init__(self, encoder, decoder, **kwargs):\n",
        "        super(VAE, self).__init__(**kwargs)\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.total_loss_tracker = tf.keras.metrics.Mean(name=\"loss\")\n",
        "        self.recon_loss_tracker = tf.keras.metrics.Mean(name=\"recon_loss\")\n",
        "        self.kl_loss_tracker = tf.keras.metrics.Mean(name=\"kl_loss\")\n",
        "\n",
        "    def call(self, inputs):\n",
        "        z_mean, z_log_var, z = self.encoder(inputs)\n",
        "        return self.decoder(z)\n",
        "\n",
        "    def compute_losses(self, data):\n",
        "        z_mean, z_log_var, z = self.encoder(data)\n",
        "        reconstruction = self.decoder(z)\n",
        "        bce = tf.keras.losses.binary_crossentropy(data, reconstruction)\n",
        "        reconstruction_loss = tf.reduce_mean(tf.reduce_sum(bce, axis=(1, 2)))\n",
        "        kl_loss = -0.5 * tf.reduce_mean(\n",
        "            tf.reduce_sum(1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var), axis=1)\n",
        "        )\n",
        "        total_loss = reconstruction_loss + kl_loss\n",
        "        return total_loss, reconstruction_loss, kl_loss\n",
        "\n",
        "    def train_step(self, data):\n",
        "        if isinstance(data, tuple):\n",
        "            data = data[0]\n",
        "        with tf.GradientTape() as tape:\n",
        "            total_loss, reconstruction_loss, kl_loss = self.compute_losses(data)\n",
        "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
        "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
        "        self.total_loss_tracker.update_state(total_loss)\n",
        "        self.recon_loss_tracker.update_state(reconstruction_loss)\n",
        "        self.kl_loss_tracker.update_state(kl_loss)\n",
        "        return {\n",
        "            \"loss\": self.total_loss_tracker.result(),\n",
        "            \"recon_loss\": self.recon_loss_tracker.result(),\n",
        "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
        "        }\n",
        "\n",
        "    def test_step(self, data):\n",
        "        if isinstance(data, tuple):\n",
        "            data = data[0]\n",
        "        total_loss, reconstruction_loss, kl_loss = self.compute_losses(data)\n",
        "        self.total_loss_tracker.update_state(total_loss)\n",
        "        self.recon_loss_tracker.update_state(reconstruction_loss)\n",
        "        self.kl_loss_tracker.update_state(kl_loss)\n",
        "        return {\n",
        "            \"val_loss\": self.total_loss_tracker.result(),\n",
        "            \"val_recon_loss\": self.recon_loss_tracker.result(),\n",
        "            \"val_kl_loss\": self.kl_loss_tracker.result(),\n",
        "        }\n",
        "\n",
        "# --------------------------\n",
        "# COMPILAR E TREINAR\n",
        "# --------------------------\n",
        "vae = VAE(encoder, decoder)\n",
        "vae.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4))\n",
        "\n",
        "if not os.path.exists(vae_weights_path):\n",
        "    print(\"🧠 Treinando VAE (versão final compatível)...\")\n",
        "    vae.fit(\n",
        "        train_gen,\n",
        "        validation_data=val_gen,\n",
        "        epochs=VAE_EPOCHS,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # ⚙️ build antes de salvar pesos\n",
        "    vae.build((None, *input_shape))\n",
        "\n",
        "    # salvar nos formatos modernos\n",
        "    vae.encoder.save(encoder_path)\n",
        "    vae.decoder.save(decoder_path)\n",
        "    vae.save_weights(vae_weights_path)\n",
        "\n",
        "    print(\"✅ VAE treinado e salvo com sucesso (.keras / .weights.h5)\")\n",
        "else:\n",
        "    print(\"⚙️ Carregando pesos VAE existentes...\")\n",
        "    vae.build((None, *input_shape))\n",
        "    vae.encoder.load_weights(encoder_path, skip_mismatch=True)\n",
        "    vae.decoder.load_weights(decoder_path, skip_mismatch=True)\n",
        "    print(\"✅ Modelos encoder/decoder carregados.\")\n"
      ],
      "metadata": {
        "id": "XYSAlGgQy2b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f5a5b611-c2fd-4d2b-8f98-994d226bdcbe"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Etapa 5: Criando e treinando o Autoencoder Variacional (VAE) – versão FINAL compatível com TF 2.15 / Keras 3.\n",
            "Found 1125 images belonging to 5 classes.\n",
            "Found 125 images belonging to 5 classes.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"encoder\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"encoder\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ encoder_input       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m3\u001b[0m)                │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m,  │        \u001b[38;5;34m896\u001b[0m │ encoder_input[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │     \u001b[38;5;34m18,496\u001b[0m │ conv2d_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │     \u001b[38;5;34m73,856\u001b[0m │ conv2d_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100352\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ conv2d_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │ \u001b[38;5;34m25,690,368\u001b[0m │ flatten_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ z_mean (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │     \u001b[38;5;34m16,448\u001b[0m │ dense_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ z_log_var (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │     \u001b[38;5;34m16,448\u001b[0m │ dense_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ z (\u001b[38;5;33mLambda\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ z_mean[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
              "│                     │                   │            │ z_log_var[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ encoder_input       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │ encoder_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │ conv2d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │ conv2d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100352</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">25,690,368</span> │ flatten_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ z_mean (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> │ dense_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ z_log_var (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> │ dense_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ z (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ z_mean[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
              "│                     │                   │            │ z_log_var[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m25,816,512\u001b[0m (98.48 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,816,512</span> (98.48 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m25,816,512\u001b[0m (98.48 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,816,512</span> (98.48 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"decoder\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"decoder\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ z_sampling (\u001b[38;5;33mInputLayer\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50176\u001b[0m)          │     \u001b[38;5;34m3,261,440\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ reshape_2 (\u001b[38;5;33mReshape\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_transpose_8              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
              "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_transpose_9              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m73,792\u001b[0m │\n",
              "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_transpose_10             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │        \u001b[38;5;34m18,464\u001b[0m │\n",
              "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_transpose_11             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │           \u001b[38;5;34m867\u001b[0m │\n",
              "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)               │                        │               │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ z_sampling (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50176</span>)          │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,261,440</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ reshape_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_transpose_8              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_transpose_9              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,792</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_transpose_10             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,464</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_transpose_11             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">867</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)               │                        │               │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,428,419\u001b[0m (13.08 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,428,419</span> (13.08 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,428,419\u001b[0m (13.08 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,428,419</span> (13.08 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🧠 Treinando VAE (versão final compatível)...\n",
            "Epoch 1/2\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 5s/step - kl_loss: 1.8715 - loss: 34718.9180 - recon_loss: 34717.0469 - val_val_kl_loss: 217.6734 - val_val_loss: 33878.2109 - val_val_recon_loss: 33660.5391\n",
            "Epoch 2/2\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 5s/step - kl_loss: 505.3818 - loss: 31762.4980 - recon_loss: 31257.1152 - val_val_kl_loss: 64.4288 - val_val_loss: 28218.8828 - val_val_recon_loss: 28154.4551\n",
            "✅ VAE treinado e salvo com sucesso (.keras / .weights.h5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------\n",
        "# 6 - Criar augmentações (novas abordagens)\n",
        "# --------------------------\n",
        "print(\"\\nEtapa 6: criando augmentações (reconstruções VAE, interpolação latente, SpecAugment, spectral mix)\")\n",
        "\n",
        "ensure_empty_dir(AUG_DIR)\n",
        "for g in sorted(os.listdir(IMG_DIR)):\n",
        "    os.makedirs(os.path.join(AUG_DIR, g), exist_ok=True)\n",
        "\n",
        "# 6A: Reconstruções ruidosas (VAE reconstruction of noisy input)\n",
        "def reconstruct_with_vae(X, batch=32):\n",
        "    recs = vae.predict(X, batch_size=batch)\n",
        "    return recs\n",
        "\n",
        "# gerar reconstruções para cada imagem de treino (uma por amostra)\n",
        "for i, p in enumerate(tqdm(train_paths)):\n",
        "    cls = train_y[i]\n",
        "    # carregar imagem\n",
        "    img = Image.open(os.path.join(IMG_DIR, p)).convert(\"RGB\").resize((IMG_WIDTH, IMG_HEIGHT))\n",
        "    arr = np.array(img, dtype=np.float32)/255.0\n",
        "    noisy = add_noise(np.expand_dims(arr,0), NOISE_FACTOR)\n",
        "    rec = vae.predict(noisy)[0]\n",
        "    outname = os.path.splitext(os.path.basename(p))[0] + \"_vae_rec.jpg\"\n",
        "    Image.fromarray((rec*255).astype(np.uint8)).save(os.path.join(AUG_DIR, cls, outname))\n",
        "\n",
        "# 6B: Interpolação no espaço latente (entre pares da mesma classe e entre classes similares)\n",
        "N_INTERP_PER_CLASS = 2\n",
        "# Criar encoder model (input image -> z_mean) para obter médias latentes para interpolação\n",
        "encoder_model = models.Model(inputs, z_mean)  # usar z_mean (determinístico) para interpolar de forma estável\n",
        "\n",
        "for cls in sorted(set(train_y)):\n",
        "    class_indices = [i for i,lab in enumerate(train_y) if lab==cls]\n",
        "    if len(class_indices) < 2: continue\n",
        "    chosen = np.random.choice(class_indices, size=min(len(class_indices), 10), replace=False)\n",
        "    for k in range(N_INTERP_PER_CLASS):\n",
        "        a,b = np.random.choice(chosen, size=2, replace=False)\n",
        "        img_a = np.array(Image.open(os.path.join(IMG_DIR, train_paths[a])).convert(\"RGB\").resize((IMG_WIDTH,IMG_HEIGHT)), dtype=np.float32)/255.0\n",
        "        img_b = np.array(Image.open(os.path.join(IMG_DIR, train_paths[b])).convert(\"RGB\").resize((IMG_WIDTH,IMG_HEIGHT)), dtype=np.float32)/255.0\n",
        "        za = encoder_model.predict(img_a[np.newaxis,...])[0]\n",
        "        zb = encoder_model.predict(img_b[np.newaxis,...])[0]\n",
        "        alpha = np.random.uniform(0.25, 0.75)\n",
        "        zint = alpha * za + (1-alpha) * zb\n",
        "        rec = decoder.predict(zint[np.newaxis,...])[0]\n",
        "        outname = f\"interp_{k}_{os.path.basename(train_paths[a])}_{os.path.basename(train_paths[b])}.jpg\"\n",
        "        Image.fromarray((np.clip(rec,0,1)*255).astype(np.uint8)).save(os.path.join(AUG_DIR, cls, outname))\n",
        "\n",
        "# 6C: SpecAugment (aplicado diretamente nos espectrogramas antes de salvar)\n",
        "def spec_augment_image(img_arr, time_masks=SPEC_AUG_TIME_MASKS, freq_masks=SPEC_AUG_FREQ_MASKS, max_time_mask_pct=0.2, max_freq_mask_pct=0.15):\n",
        "    # img_arr in [0,1], shape (H,W,C) but SpecAugment manipulates spectral axis (H=n_mels) and time axis (W)\n",
        "    img = img_arr.copy()\n",
        "    H, W = img.shape[0], img.shape[1]\n",
        "    for _ in range(time_masks):\n",
        "        t = int(np.random.uniform(0.0, max_time_mask_pct) * W)\n",
        "        t0 = np.random.randint(0, max(1, W - t + 1))\n",
        "        img[:, t0:t0+t, :] = 0\n",
        "    for _ in range(freq_masks):\n",
        "        f = int(np.random.uniform(0.0, max_freq_mask_pct) * H)\n",
        "        f0 = np.random.randint(0, max(1, H - f + 1))\n",
        "        img[f0:f0+f, :, :] = 0\n",
        "    return img\n",
        "\n",
        "# Aplicar SpecAugment a algumas imagens de treino e salvar\n",
        "N_SPEC_AUG_PER_CLASS = 2\n",
        "for cls in sorted(set(train_y)):\n",
        "    class_indices = [i for i,lab in enumerate(train_y) if lab==cls]\n",
        "    chosen = np.random.choice(class_indices, size=min(len(class_indices), 20), replace=False)\n",
        "    for i_idx in chosen[:N_SPEC_AUG_PER_CLASS]:\n",
        "        p = train_paths[i_idx]\n",
        "        arr = np.array(Image.open(os.path.join(IMG_DIR, p)).convert(\"RGB\").resize((IMG_WIDTH, IMG_HEIGHT)), dtype=np.float32)/255.0\n",
        "        aug = spec_augment_image(arr)\n",
        "        outname = os.path.splitext(os.path.basename(p))[0] + \"_specaug.jpg\"\n",
        "        Image.fromarray((np.clip(aug,0,1)*255).astype(np.uint8)).save(os.path.join(AUG_DIR, cls, outname))\n",
        "\n",
        "# 6D: Spectral Mix (linear mix of two spectrogram images) - naive mix (hard label use original or duplicate)\n",
        "N_MIX_PER_CLASS = 2\n",
        "for cls in sorted(set(train_y)):\n",
        "    class_indices = [i for i,lab in enumerate(train_y) if lab==cls]\n",
        "    if len(class_indices) < 2: continue\n",
        "    chosen = np.random.choice(class_indices, size=min(len(class_indices), 20), replace=False)\n",
        "    for k in range(N_MIX_PER_CLASS):\n",
        "        a,b = np.random.choice(chosen, size=2, replace=False)\n",
        "        arr_a = np.array(Image.open(os.path.join(IMG_DIR, train_paths[a])).convert(\"RGB\").resize((IMG_WIDTH,IMG_HEIGHT)), dtype=np.float32)/255.0\n",
        "        arr_b = np.array(Image.open(os.path.join(IMG_DIR, train_paths[b])).convert(\"RGB\").resize((IMG_WIDTH,IMG_HEIGHT)), dtype=np.float32)/255.0\n",
        "        alpha = np.random.uniform(0.3, 0.7)\n",
        "        mixed = alpha*arr_a + (1-alpha)*arr_b\n",
        "        outname = f\"mix_{k}_{os.path.basename(train_paths[a])}_{os.path.basename(train_paths[b])}.jpg\"\n",
        "        Image.fromarray((np.clip(mixed,0,1)*255).astype(np.uint8)).save(os.path.join(AUG_DIR, cls, outname))\n",
        "\n",
        "# 6E: finalmente, copiamos os originais para AUG_DIR (mantém originais + artificially generated)\n",
        "for p, y in zip(train_paths, train_y):\n",
        "    src = os.path.join(IMG_DIR, p)\n",
        "    dst = os.path.join(AUG_DIR, y, os.path.basename(p))\n",
        "    if not os.path.exists(dst):\n",
        "        shutil.copy(src, dst)\n",
        "\n",
        "# salvar resumo de quantos arquivos por classe no AUG_DIR\n",
        "aug_counts = {g: len([f for f in os.listdir(os.path.join(AUG_DIR,g)) if f.lower().endswith(\".jpg\")]) for g in os.listdir(AUG_DIR)}\n",
        "pd.DataFrame(list(aug_counts.items()), columns=[\"genre\",\"aug_images\"]).to_csv(os.path.join(ROOT_DIR, \"aug_image_counts_unit2.csv\"), index=False)\n",
        "print(\"Augmentation concluída. Counts saved to aug_image_counts_unit2.csv\")"
      ],
      "metadata": {
        "id": "bWP5r5F1y7uI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "outputId": "e1225a53-53b6-47fc-f169-d82dbd91fde8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Etapa 6: criando augmentações (reconstruções VAE, interpolação latente, SpecAugment, spectral mix)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_paths' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-281224329.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# gerar reconstruções para cada imagem de treino (uma por amostra)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# carregar imagem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_paths' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------\n",
        "# 7 - Testes: treinar 2 CNNs\n",
        "#   - CNN A: VGG16 transfer learning com dados originais (baseline)\n",
        "#   - CNN B: VGG16 transfer learning com dados originais + AUG_DIR\n",
        "# --------------------------\n",
        "print(\"\\nEtapa 7: treinar CNNs baseline e augmented\")\n",
        "\n",
        "# Funções auxiliares para coletar arquivos\n",
        "def collect_files_labels(root):\n",
        "    files, labels = [], []\n",
        "    for cls in sorted(os.listdir(root)):\n",
        "        cls_dir = os.path.join(root, cls)\n",
        "        if not os.path.isdir(cls_dir): continue\n",
        "        for f in os.listdir(cls_dir):\n",
        "            if f.lower().endswith(\".jpg\"):\n",
        "                files.append(os.path.join(cls_dir, f))\n",
        "                labels.append(cls)\n",
        "    return files, labels\n",
        "\n",
        "orig_files, orig_labels = collect_files_labels(IMG_DIR)\n",
        "aug_files, aug_labels = collect_files_labels(AUG_DIR)\n",
        "\n",
        "# Criar splits (para comparação justa manter o mesmo test set - usar test_paths criados anteriormente)\n",
        "# We'll use test_paths list (relative paths) to define test set file paths in IMG_DIR\n",
        "test_file_paths = [os.path.join(IMG_DIR, p) for p in test_paths]\n",
        "\n",
        "# Create function to split train/val for baseline using orig_files excluding test_files\n",
        "def split_files_for_training(files, labels, test_file_paths, val_frac=0.2):\n",
        "    # filter out test\n",
        "    files_filtered, labels_filtered = [], []\n",
        "    for f, l in zip(files, labels):\n",
        "        if os.path.abspath(f) in [os.path.abspath(x) for x in test_file_paths]:\n",
        "            continue\n",
        "        files_filtered.append(f); labels_filtered.append(l)\n",
        "    tr_files, val_files, tr_labels, val_labels = train_test_split(files_filtered, labels_filtered, test_size=val_frac, stratify=labels_filtered, random_state=RANDOM_STATE)\n",
        "    return tr_files, val_files, tr_labels, val_labels\n",
        "\n",
        "train_files_base, val_files_base, train_labels_base, val_labels_base = split_files_for_training(orig_files, orig_labels, test_file_paths)\n",
        "train_files_aug, val_files_aug, train_labels_aug, val_labels_aug = split_files_for_training(aug_files, aug_labels, test_file_paths)\n",
        "\n",
        "print(\"Baseline train size:\", len(train_files_base), \"val:\", len(val_files_base), \"test:\", len(test_file_paths))\n",
        "print(\"Augmented train size:\", len(train_files_aug), \"val:\", len(val_files_aug), \"test:\", len(test_file_paths))\n",
        "\n",
        "# Generator Keras Sequence\n",
        "from tensorflow.keras.utils import Sequence\n",
        "class ImageSequence(Sequence):\n",
        "    def __init__(self, files, labels, le, batch_size=BATCH_SIZE, shuffle=True, augment=False):\n",
        "        self.files = files\n",
        "        self.labels = np.array(labels)\n",
        "        self.le = le\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.augment = augment\n",
        "        self.indexes = np.arange(len(self.files))\n",
        "        self.on_epoch_end()\n",
        "    def __len__(self):\n",
        "        return math.ceil(len(self.files)/self.batch_size)\n",
        "    def __getitem__(self, idx):\n",
        "        batch_idx = self.indexes[idx*self.batch_size:(idx+1)*self.batch_size]\n",
        "        batch_files = [self.files[i] for i in batch_idx]\n",
        "        batch_labels = self.labels[batch_idx]\n",
        "        imgs = []\n",
        "        for p in batch_files:\n",
        "            img = Image.open(p).convert(\"RGB\").resize((IMG_WIDTH,IMG_HEIGHT))\n",
        "            arr = np.array(img, dtype=np.float32)/255.0\n",
        "            if self.augment:\n",
        "                # apply random small transforms: horizontal flip, small brightness jitter, spec augment occasionally\n",
        "                if random.random() < 0.1:\n",
        "                    arr = np.fliplr(arr)\n",
        "                if random.random() < 0.2:\n",
        "                    arr = np.clip(arr + 0.03 * np.random.randn(*arr.shape), 0, 1)\n",
        "            imgs.append(arr)\n",
        "        X = np.stack(imgs)\n",
        "        y = to_categorical(self.le.transform(batch_labels), num_classes=len(self.le.classes_))\n",
        "        return X, y\n",
        "    def on_epoch_end(self):\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "# label encoder based on classes found\n",
        "le_classes = LabelEncoder()\n",
        "le_classes.fit(sorted(os.listdir(IMG_DIR)))\n",
        "\n",
        "# Create generators\n",
        "train_gen_base = ImageSequence(train_files_base, train_labels_base, le_classes, batch_size=BATCH_SIZE, shuffle=True, augment=False)\n",
        "val_gen_base = ImageSequence(val_files_base, val_labels_base, le_classes, batch_size=BATCH_SIZE, shuffle=False, augment=False)\n",
        "train_gen_aug = ImageSequence(train_files_aug, train_labels_aug, le_classes, batch_size=BATCH_SIZE, shuffle=True, augment=True)\n",
        "val_gen_aug = ImageSequence(val_files_aug, val_labels_aug, le_classes, batch_size=BATCH_SIZE, shuffle=False, augment=False)\n",
        "test_gen = ImageSequence(test_file_paths, test_y, le_classes, batch_size=BATCH_SIZE, shuffle=False, augment=False)\n",
        "\n",
        "# Build VGG16 transfer model factory\n",
        "def build_vgg_transfer(num_classes, train_base=False):\n",
        "    base = VGG16(include_top=False, weights='imagenet', input_shape=(IMG_WIDTH,IMG_HEIGHT,3))\n",
        "    base.trainable = train_base\n",
        "    inp = layers.Input(shape=(IMG_WIDTH,IMG_HEIGHT,3))\n",
        "    x = base(inp, training=False)\n",
        "    x = layers.Flatten()(x)\n",
        "    x = layers.Dense(512, activation='relu')(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "    out = layers.Dense(num_classes, activation='softmax')(x)\n",
        "    model = models.Model(inp, out)\n",
        "    model.compile(optimizer=optimizers.Adam(1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "num_classes = len(le_classes.classes_)\n",
        "print(\"Num classes:\", num_classes)\n",
        "\n",
        "# Train baseline\n",
        "print(\"Treinando VGG16 baseline (originais)...\")\n",
        "vgg_base = build_vgg_transfer(num_classes, train_base=False)\n",
        "es = callbacks.EarlyStopping(patience=4, restore_best_weights=True)\n",
        "history_base = vgg_base.fit(train_gen_base, epochs=CLASS_EPOCHS, validation_data=val_gen_base, callbacks=[es])\n",
        "vgg_base.save(os.path.join(MODEL_DIR, \"vgg_base_unit2.h5\"))\n",
        "\n",
        "# Evaluate baseline\n",
        "def evaluate_keras_model(model, seq):\n",
        "    y_true, y_pred, y_prob = [], [], []\n",
        "    for Xb, yb in seq:\n",
        "        probs = model.predict(Xb)\n",
        "        preds = np.argmax(probs, axis=1)\n",
        "        y_pred.extend(preds.tolist())\n",
        "        y_prob.extend(probs.tolist())\n",
        "        y_true.extend(np.argmax(yb, axis=1).tolist())\n",
        "    return np.array(y_true), np.array(y_pred), np.array(y_prob)\n",
        "\n",
        "y_true_base, y_pred_base, y_prob_base = evaluate_keras_model(vgg_base, test_gen)\n",
        "acc_base = accuracy_score(y_true_base, y_pred_base)\n",
        "f1_base = f1_score(y_true_base, y_pred_base, average='macro')\n",
        "print(\"Baseline: Acc\", acc_base, \"F1\", f1_base)\n",
        "\n",
        "# Train augmented\n",
        "print(\"Treinando VGG16 com dataset aumentado...\")\n",
        "vgg_aug = build_vgg_transfer(num_classes, train_base=False)\n",
        "history_aug = vgg_aug.fit(train_gen_aug, epochs=CLASS_EPOCHS, validation_data=val_gen_aug, callbacks=[es])\n",
        "vgg_aug.save(os.path.join(MODEL_DIR, \"vgg_aug_unit2.h5\"))\n",
        "\n",
        "y_true_aug, y_pred_aug, y_prob_aug = evaluate_keras_model(vgg_aug, test_gen)\n",
        "acc_aug = accuracy_score(y_true_aug, y_pred_aug)\n",
        "f1_aug = f1_score(y_true_aug, y_pred_aug, average='macro')\n",
        "print(\"Augmented: Acc\", acc_aug, \"F1\", f1_aug)"
      ],
      "metadata": {
        "id": "XMUlI35sy_tB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------\n",
        "# 8 - Resultados: tabela, ROC e matrizes de confusão\n",
        "# --------------------------\n",
        "print(\"\\nEtapa 8: Gerando métricas, curvas ROC e matrizes de confusão (sem PDF).\")\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve, auc\n",
        "from sklearn.preprocessing import label_binarize\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Criação da tabela de métricas\n",
        "y_test_bin = label_binarize(y_true_base, classes=np.arange(num_classes))\n",
        "try:\n",
        "    auc_base = roc_auc_score(y_test_bin, y_prob_base, average='macro')\n",
        "except Exception:\n",
        "    auc_base = np.nan\n",
        "try:\n",
        "    auc_aug = roc_auc_score(y_test_bin, y_prob_aug, average='macro')\n",
        "except Exception:\n",
        "    auc_aug = np.nan\n",
        "\n",
        "metrics_df = pd.DataFrame([\n",
        "    [\"VGG16 (baseline)\", acc_base, f1_base, auc_base],\n",
        "    [\"VGG16 (augmented)\", acc_aug, f1_aug, auc_aug]\n",
        "], columns=[\"Model\", \"Accuracy\", \"F1_macro\", \"AUC_macro\"])\n",
        "\n",
        "# Salvar tabela\n",
        "metrics_path = os.path.join(RESULTS_DIR, \"metrics_comparison_unit2.csv\")\n",
        "metrics_df.to_csv(metrics_path, index=False)\n",
        "print(\"\\n📊 Tabela de métricas:\")\n",
        "print(metrics_df)\n",
        "print(f\"\\nTabela salva em: {metrics_path}\")\n",
        "\n",
        "# --------------------------\n",
        "# Curvas ROC\n",
        "# --------------------------\n",
        "def multiclass_roc(y_true, y_prob, n_classes):\n",
        "    y_bin = label_binarize(y_true, classes=np.arange(n_classes))\n",
        "    fpr, tpr, roc_auc = {}, {}, {}\n",
        "    for i in range(n_classes):\n",
        "        try:\n",
        "            fpr[i], tpr[i], _ = roc_curve(y_bin[:, i], np.array(y_prob)[:, i])\n",
        "            roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "        except:\n",
        "            fpr[i], tpr[i], roc_auc[i] = None, None, None\n",
        "    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes) if fpr[i] is not None]))\n",
        "    mean_tpr = np.zeros_like(all_fpr)\n",
        "    for i in range(n_classes):\n",
        "        if fpr[i] is not None:\n",
        "            mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
        "    mean_tpr /= n_classes\n",
        "    fpr[\"macro\"], tpr[\"macro\"], roc_auc[\"macro\"] = all_fpr, mean_tpr, auc(all_fpr, mean_tpr)\n",
        "    return fpr, tpr, roc_auc\n",
        "\n",
        "fpr_b, tpr_b, roc_auc_b = multiclass_roc(y_true_base, y_prob_base, num_classes)\n",
        "fpr_a, tpr_a, roc_auc_a = multiclass_roc(y_true_aug, y_prob_aug, num_classes)\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.plot(fpr_b[\"macro\"], tpr_b[\"macro\"], '--', label=f'Baseline (AUC={roc_auc_b[\"macro\"]:.3f})')\n",
        "plt.plot(fpr_a[\"macro\"], tpr_a[\"macro\"], '-.', label=f'Augmented (AUC={roc_auc_a[\"macro\"]:.3f})')\n",
        "plt.plot([0,1],[0,1],'k--')\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"ROC Curve - Comparação (Macro Average)\")\n",
        "plt.legend()\n",
        "plt.grid(alpha=0.3)\n",
        "roc_path = os.path.join(RESULTS_DIR, \"roc_comparison.png\")\n",
        "plt.savefig(roc_path, dpi=200)\n",
        "plt.close()\n",
        "print(f\"✅ Curva ROC salva em: {roc_path}\")\n",
        "\n",
        "# --------------------------\n",
        "# Matrizes de confusão\n",
        "# --------------------------\n",
        "cm_base = confusion_matrix(y_true_base, y_pred_base)\n",
        "cm_aug  = confusion_matrix(y_true_aug, y_pred_aug)\n",
        "\n",
        "# Baseline\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.heatmap(cm_base, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "            xticklabels=le_classes.classes_, yticklabels=le_classes.classes_)\n",
        "plt.title(\"Matriz de Confusão - CNN Base\")\n",
        "plt.xlabel(\"Predito\"); plt.ylabel(\"Real\")\n",
        "cm_base_path = os.path.join(RESULTS_DIR, \"cm_baseline.png\")\n",
        "plt.savefig(cm_base_path, dpi=200)\n",
        "plt.close()\n",
        "\n",
        "# Augmented\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.heatmap(cm_aug, annot=True, fmt=\"d\", cmap=\"Greens\",\n",
        "            xticklabels=le_classes.classes_, yticklabels=le_classes.classes_)\n",
        "plt.title(\"Matriz de Confusão - CNN com Augmentation\")\n",
        "plt.xlabel(\"Predito\"); plt.ylabel(\"Real\")\n",
        "cm_aug_path = os.path.join(RESULTS_DIR, \"cm_augmented.png\")\n",
        "plt.savefig(cm_aug_path, dpi=200)\n",
        "plt.close()\n",
        "\n",
        "print(f\"✅ Matrizes salvas em:\\n - {cm_base_path}\\n - {cm_aug_path}\")\n",
        "\n",
        "print(\"\\n🎯 Resultados finais concluídos! Verifique os arquivos na pasta 'results_unit2'\")\n"
      ],
      "metadata": {
        "id": "SOjhLBn401Pq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}